{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt #for the plots\n",
    "import seaborn as sns \n",
    "import re\n",
    "import OurFunctions as of\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_original = pd.read_csv(os.path.join('DataSets','Phenotypic Datasets','ASD','ASD_phenotypic.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the overall dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 1112 subjects and has 74 features.\n",
    "\n",
    " By a fast view we can see that there are both categorical and numerical values and there are missing values. Also, we can see the presence of the categories DX_GROUP and DSM_IV_TR, that are described from the ABIDE dataset legend as diagnostic, so we will further remove them from the dataset for the model predictor construction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a better view of the information we display the names of the features and the respective types and quantity of non-null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_original.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is an important presence of missing values. Also, there are both numerical type features and object type (which is the default way to label the categorical data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a better view of the distribution of the null values, we check the presence of missing values catalogated as None or numpy.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of the missing values\n",
    "nan_values = ASD_phenotypic_original.isna().sum()\n",
    "nan_sorted = nan_values.sort_values(ascending=False)\n",
    "\n",
    "# We implemented a function \"select_columns\", that is able to define wich columns are numerical\n",
    "# and which ones are categorical (also redefine the objects as categorical in the dataset)\n",
    "numeric_columns, categorical_columns, ASD_phenotypic_original = of.select_columns(ASD_phenotypic_original)\n",
    "\n",
    "# We plot the distribution of missing values, with the specification of numeric and categorical columns\n",
    "of.plot_missing_values(nan_sorted, numeric_columns, legend=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the majority of the features the amount of missing values is not depreciable, so we can say that the information that is stored in the feature is not enough to create a reliable classier/cluster algortihm based on it. We will consider eliminate some of these features to avoid introduce misleading information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look on the general statistics for the numerical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_original.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice the presence of \"-9999\" as minimum value for different features, a value that is commonly used to denote missing data or values out of range, so it should be better to consider them as NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an overall view of the dataset, let's start to work on it in order to clean it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BALANCING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DX_GROUP and DSM_IV_TR are our targets.\n",
    "DX_GROUP contains info about the presence (or not) of autism spectrum.\n",
    "DSM_IV_TR specifyes which kind of autism. \n",
    "However, in our invastigation, the DSM_IV_TR results negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcola il conteggio delle classi per DX_GROUP\n",
    "class_counts_DX_GROUP = ASD_phenotypic_original['DX_GROUP'].value_counts()\n",
    "\n",
    "# Stampa il conteggio delle classi per DX_GROUP\n",
    "print(\"Conteggio delle classi per DX_GROUP:\")\n",
    "print(class_counts_DX_GROUP)\n",
    "\n",
    "# Visualizza la distribuzione delle classi per DX_GROUP\n",
    "class_counts_DX_GROUP.plot(kind='bar', color='blue')\n",
    "plt.title('Distribuzione delle classi per DX_GROUP')\n",
    "plt.xlabel('Classe')\n",
    "plt.ylabel('Numero di campioni')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Calcola le proporzioni delle classi per DX_GROUP\n",
    "class_proportions_DX_GROUP = ASD_phenotypic_original['DX_GROUP'].value_counts(normalize=True)\n",
    "\n",
    "# Stampa le proporzioni delle classi per DX_GROUP\n",
    "print(\"\\nProporzioni delle classi per DX_GROUP:\")\n",
    "print(class_proportions_DX_GROUP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DX_GROUP is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we decided to apart the features that give the diagnosis of the subjects (DX_GROUP and DSM_IV_TR), in order to use them as the control labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop  columns DX_GROUP e DSM_IV_TR from the original ASD_phenotypic \n",
    "ASD_phenotypic = ASD_phenotypic_original.drop(columns=['DX_GROUP', 'DSM_IV_TR'])\n",
    "\n",
    "# Store them in a new dataset called ASD_clinical\n",
    "ASD_clinical = ASD_phenotypic_original[['DX_GROUP']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_clinical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we decide to drop SUB_ID, as it only store the information about the ID of the subject. But before we check if there aren't replicated subjects. Then if we don't find any duplicate, we can simply drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are duplicate values in the 'SUB_ID' column\n",
    "duplicate_ids = ASD_phenotypic['SUB_ID'].duplicated(keep=False)\n",
    "\n",
    "# Get the unique duplicate IDs\n",
    "unique_duplicate_ids = ASD_phenotypic.loc[duplicate_ids, 'SUB_ID'].unique()\n",
    "\n",
    "#Drop column if there aren't duplicates\n",
    "if len(unique_duplicate_ids) == 0:\n",
    "    ASD_phenotypic = ASD_phenotypic.drop(columns=['SUB_ID'])\n",
    "    print(\"SUB_ID was dropped\")\n",
    "else:\n",
    "    print(\"There are replicated values:\" + str(unique_duplicate_ids))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a real count of the amount of missing values per feature, we change the -9999 values present in the overall data to np.NaN (we can make this because we know from the datasheets that -9999 is a value out of range for all the features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ASD_phenotypic:\n",
    "    \n",
    "    # Replace -9999 and \"-9999\" with NaN\n",
    "    ASD_phenotypic[column] = ASD_phenotypic[column].replace(['-9999', -9999], np.NaN)\n",
    "    \n",
    "\n",
    "'''We checked if the presence changing -9999 as NaN at the starting point produce relevant changes\n",
    "in distribution of Missing Values in Dataset and subesequent brutal filtering and we found that\n",
    "the changes are negligible. '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we said before, noticed the huge amount of missing values in dataset, it's reasonable to delete apriori those features containing an high percentage of missing values. We decided to fix as a threshold to conserve only the features that has a maximum of the 70% of missing values, in order to proceed in a more easy and consistent way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of the missing values\n",
    "nan_values = ASD_phenotypic.isna().sum()\n",
    "nan_sorted = nan_values.sort_values(ascending=False)\n",
    "\n",
    "# We implemented a function \"select_columns\", that is able to define wich columns are numerical\n",
    "# and which ones are categorical (also redefine the objects as categorical in the dataset)\n",
    "numeric_columns, categorical_columns, ASD_phenotypic = of.select_columns(ASD_phenotypic)\n",
    "\n",
    "# We plot the distribution of missing values, with the specification of numeric and categorical columns\n",
    "of.plot_missing_values(nan_sorted, numeric_columns, legend=True)\n",
    "plt.axvline(x=0.7 * 1112, color='red', linestyle='--', label='70% Threshold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in this way we delete many features, but we still conserving the most important ones. If we analise which features have been deleted, we notice that they are mostly the results of tests, that probably haven't been performed at all the sites, so, as the aim is to create a scalable algorithm for the detection of the ASD, is better to avoid using information that is specific to the protocols of few centers.\n",
    "\n",
    "We will now apply the cut shown by the red dotted line, which we will call the \"brutal filtering\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brutal Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the maximum quantity of missinf values that are allowed\n",
    "max_missing_values = len(ASD_phenotypic) * 0.70\n",
    "\n",
    "# Trova le colonne con un numero di valori mancanti superiore al limite consentito\n",
    "columns_to_drop = []\n",
    "for column, missing_count in nan_values.items():\n",
    "    if missing_count > max_missing_values:\n",
    "        columns_to_drop.append(column)\n",
    "\n",
    "# Rimuovi le colonne con un numero di valori mancanti eccessivo\n",
    "ASD_phenotypic_filtered = ASD_phenotypic.drop(columns=columns_to_drop)\n",
    "\n",
    "# Stampa le colonne rimosse\n",
    "print(\"The columns that have been removed are:\")\n",
    "for column in columns_to_drop:\n",
    "    print(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we have to analyse only 23 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo dei valori mancanti e ordinamento\n",
    "nan_values_filtered = ASD_phenotypic_filtered.isna().sum()\n",
    "columns_with_nan_sorted_filtered = nan_values_filtered.sort_values(ascending=False)\n",
    "\n",
    "# Selezione delle colonne numeriche e categoriche\n",
    "numeric_columns_filtered, categorical_columns_filtered, ASD_phenotypic_filtered = of.select_columns(ASD_phenotypic_filtered)\n",
    "\n",
    "# Plot dei valori mancanti\n",
    "of.plot_missing_values(columns_with_nan_sorted_filtered, numeric_columns_filtered, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can investigate if there are subjects with a huge amount of missing values\n",
    "and in case delete them, applying the same criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo dei valori mancanti per soggetto anziché per feature\n",
    "nan_values_per_subject = ASD_phenotypic_filtered.T.isna().sum()\n",
    "\n",
    "# Ordinamento dei valori mancanti\n",
    "subjects_with_nan_sorted = nan_values_per_subject.sort_values(ascending=False)\n",
    "\n",
    "\n",
    "of.plot_missing_values(subjects_with_nan_sorted, nan_values_per_subject, legend=False)\n",
    "plt.ylabel('Subjects')\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we notice that we can't delete any subject, as the maximum quantity of missing values per subject is 17, which correspond to only approx 24% of the original 71 features (we are excluding the diagnosis and the subjects id)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Preprocessing of Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, in order to avoid mismatch between attributes that are the same, but wrote with upper or lower characters, we decide to unify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We make all the caracters upper for all the categorical features\n",
    "category_columns_upper = ASD_phenotypic_filtered.select_dtypes(include='category').apply(lambda x: x.str.upper())\n",
    "\n",
    "#We now modify them in the dataset\n",
    "ASD_phenotypic_filtered[category_columns_upper.columns] = category_columns_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We obtain the names of the features \n",
    "categorical_column_names = categorical_columns_filtered.tolist()\n",
    "categorical_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand better how to treat the information gived by this categorical variables we are interested in know which values are stored in this features. We will analyze all of them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the implemented tolist, we can acced to specific elements.\n",
    "We prefer create viasual subsections in order to manage these features, but we could implement a 'for logic' in order to guarantee a correct automatic work also in case of modifications on dataset.\n",
    "\n",
    "For each categorical feature, we want to investigate the amount of informations given. We suppose that for our specific scope we could drop some uninformative features, but we want to proof it. In which way? \n",
    "- Evaluating the amount of info considering Nan as Nan\n",
    "- Changing Missing values with specific feature engineering rules\n",
    "- Evaluating the amount of info with Nan evalueted\n",
    "\n",
    "We use Entropy logic.\n",
    "If both have high level of entropy we can drop the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SITE_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SITE_ID refers to the place where the data from the subject was recluted. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accesso a una specifica colonna categorica utilizzando la lista di nomi\n",
    "specific_category_column = ASD_phenotypic_filtered[categorical_column_names[0]].value_counts(dropna=False)\n",
    "specific_category_column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is data that has been collected from the same center that we decide to unify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a function to replace the categories for the indicated cases\n",
    "\n",
    "def replace_categories(category):\n",
    "    if \"UCLA\" in category:\n",
    "        return \"UCLA\"\n",
    "    if \"LEUVEN\" in category:\n",
    "        return \"LEUVEN\"\n",
    "    if \"UM\" in category:\n",
    "        return \"UM\"\n",
    "    else:\n",
    "        return category\n",
    "\n",
    "# Then we apply the replace function\n",
    "ASD_phenotypic_filtered[categorical_column_names[0]] = ASD_phenotypic_filtered[categorical_column_names[0]].apply(replace_categories).astype('category')\n",
    "\n",
    "# Now we check the new order\n",
    "specific_category_column = ASD_phenotypic_filtered[categorical_column_names[0]].value_counts(dropna=False)\n",
    "specific_category_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HANDEDNESS_CATEGORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HANDEDNESS_CATEGORY refers to the handedness of the subject. We don't really know if there is a correlation or not between the Autism Disease and the handnedness of the subject and as it is a caracteristic of the subject itselfs and not of the specific site of analysis as in the previous case, we decide to work with this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accesso a una specifica colonna categorica utilizzando la lista di nomi\n",
    "specific_category_column = ASD_phenotypic_filtered[categorical_column_names[1]].value_counts(dropna=False)\n",
    "specific_category_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are incongruences for the Ambidextreus group, so we will replace them (Mixed and L->R) for Ambi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to replace categories and NaN values\n",
    "def replace_categories_and_nan(category):\n",
    "    if category in ['MIXED', 'L->R']:\n",
    "        return 'AMBI'\n",
    "    else:\n",
    "        return category\n",
    "\n",
    "# Apply the custom function to the categorical column\n",
    "ASD_phenotypic_filtered[categorical_column_names[1]] = ASD_phenotypic_filtered[categorical_column_names[1]].apply(replace_categories_and_nan).astype('category')\n",
    "\n",
    "# Display the new result\n",
    "specific_category_column = ASD_phenotypic_filtered[categorical_column_names[1]].value_counts(dropna=False)\n",
    "specific_category_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be applied at the final????\n",
    "\n",
    "We can see that we have values for R, L and Ambi, Mixed, L->R. The dataset include as a feature also a handness score where right-handed subjects has positive score (max = 100), left-handed subjects negative score (min = -100) and ambidextreus subjects has 0 score. \n",
    "\n",
    "To be coherent with that categorization and can properly evaluate if one of those features contain redudant information or that can be merged in some manner, we decide to assign to R values the number \"100\", to L values the number \"-100\" and to Ambi, Mixed, L->R the number \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIQ_TEST_TYPE, VIQ_TEST_TYPE and PIQ_TEST_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIQ_TEST_TYPE, VIQ_TEST_TYPE and PIQ_TEST_TYPE refers to the type of test that each center chose to get the information of FIQ_TEST, VIQ_TEST and PIQ_TEST respectively. As we want our clustering algorithm to be as most general as possible, we want to be able to categorize subjects in despise of the test used by the centers to get the data. So we decide to drop this feature as well.\n",
    "\n",
    "Note that if in a future we will be interested in to analyze if there are differences between the clustering score obtained using the result for each difference test we'll can retrieve the information opportunely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (2,5):\n",
    "    specific_category_column = ASD_phenotypic_filtered[categorical_column_names[i]].value_counts(dropna=False)\n",
    "    print(specific_category_column)\n",
    "    print('______________________________________\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a function to replace the categories for the indicated cases\n",
    "\n",
    "def replace_categories(category):\n",
    "    if pd.isna(category):  # Controlla se il valore è NaN\n",
    "        return category  # Se è NaN, restituisci lo stesso valore\n",
    "    if \"WASI\" in category:\n",
    "        return \"WASI\"\n",
    "    if \"WISC\" in category:\n",
    "        return \"WISC\"\n",
    "    if \"WAIS\" in category:\n",
    "        return \"WAIS\"\n",
    "    if \"DAS\" in category:\n",
    "        return \"DAS\"\n",
    "    if \"HAWIK\" in category:\n",
    "        return \"HAWIK\"\n",
    "    if \"PPVT\" in category:\n",
    "        return \"PPVT\"\n",
    "    if \"RAVENS\" in category:\n",
    "        return \"RAVENS\"\n",
    "   \n",
    "    else:\n",
    "        return category\n",
    "\n",
    "for i in range (2,5):\n",
    "    ASD_phenotypic_filtered[categorical_column_names[i]] = ASD_phenotypic_filtered[categorical_column_names[i]].apply(replace_categories).astype('category')\n",
    "    specific_category_column = ASD_phenotypic_filtered[categorical_column_names[i]].value_counts(dropna=False)\n",
    "    print(specific_category_column)\n",
    "    print('______________________________________\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CURRENT_MED_STATUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature indicates if the subject is taking any medication or not. If the subject doesn't take any medication is labeled with a \"0\" in the other case with a \"1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accesso a una specifica colonna categorica utilizzando la lista di nomi\n",
    "specific_category_column = ASD_phenotypic_filtered[categorical_column_names[5]].value_counts(dropna=False)\n",
    "specific_category_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the only attribute that is not numeric is the \"`\", we will catalogate it as a NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to replace categories and NaN values\n",
    "def replace_categories_and_nan(category):\n",
    "    if category in [\"`\"]:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return category\n",
    "\n",
    "# Apply the custom function to the categorical column\n",
    "ASD_phenotypic_filtered[categorical_column_names[5]] = ASD_phenotypic_filtered[categorical_column_names[5]].apply(replace_categories_and_nan).astype('float64')\n",
    "\n",
    "# Display the new result\n",
    "specific_category_column = ASD_phenotypic_filtered[categorical_column_names[5]].value_counts(dropna=False)\n",
    "specific_category_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the general information of the dataset once again in order to have a better view of the dataset, now that we have performed some changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_filtered.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to fullfill the missing values for all the features, based on an analysis of the information delivered by each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IQ Test Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use features FIQ, VIQ and PIQ in order to fill some values in FIQ-TEST-TYPE, VIQ-TEST-TYPE, PIQ-TEST-TYPE.\n",
    "Since the presence of more missing values in \"Type\" features, we make a comparison for each couple of features. For instance: if for FIQ there is a value and for FIQ-TEST-TYPE there is a missing one, we fill it with the MODE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista delle coppie di features da controllare\n",
    "feature_pairs = [\n",
    "    ('FIQ_TEST_TYPE', 'FIQ'),\n",
    "    ('PIQ_TEST_TYPE', 'PIQ'),\n",
    "    ('VIQ_TEST_TYPE', 'VIQ')]\n",
    "\n",
    "# Iteriamo su ogni coppia di features\n",
    "for test_type_col, score_col in feature_pairs:\n",
    "    # Iteriamo su ogni riga del DataFrame\n",
    "    for index, row in ASD_phenotypic_filtered.iterrows():\n",
    "        # Controlliamo se il valore nella colonna 'test_type_col' è mancante\n",
    "        if pd.isnull(row[test_type_col]):\n",
    "            # Se il valore nella colonna 'score_col' è presente\n",
    "            if not pd.isnull(row[score_col]):\n",
    "                # Calcoliamo la moda di 'test_type_col'\n",
    "                mode_test_type = ASD_phenotypic_filtered[test_type_col].mode()[0]\n",
    "                # Sostituiamo il valore mancante nella colonna 'test_type_col' con la moda\n",
    "                ASD_phenotypic_filtered.at[index, test_type_col] = mode_test_type\n",
    "            # Se entrambi i valori in 'test_type_col' e 'score_col' sono mancanti\n",
    "            elif pd.isnull(row[score_col]):\n",
    "                # Verifichiamo se \"NOT_AVAILABLE\" è già presente tra le categorie della colonna\n",
    "                if \"NOT_AVAILABLE\" not in ASD_phenotypic_filtered[test_type_col].cat.categories:\n",
    "                    # Aggiungiamo \"NOT_AVAILABLE\" come nuova categoria\n",
    "                    ASD_phenotypic_filtered[test_type_col] = ASD_phenotypic_filtered[test_type_col].cat.add_categories(\"NOT_AVAILABLE\")\n",
    "                # Assegniamo la categoria 'NOT_AVAILABLE' a 'test_type_col'\n",
    "                ASD_phenotypic_filtered.at[index, test_type_col] = 'NOT_AVAILABLE'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Standarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting to fill the missing values, we note that as the data for the variables FIQ, VIQ, PIQ was obtained with different tests, there are also different scales for the scores to take into account. In this way, we prefer to apply a standardization so we have all the score on the same scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For FIQ, the score scale is between 30-170 if the test taken was \"DAS\", otherwise is 50-160.\n",
    "#We will unify all the data to the larger scale, i.e. 30-170\n",
    "\n",
    "# We start defining the condition\n",
    "condition = (ASD_phenotypic_filtered['FIQ_TEST_TYPE'] != 'DAS') & (ASD_phenotypic_filtered['FIQ'] >= 50) & (ASD_phenotypic_filtered['FIQ'] <= 160)\n",
    "\n",
    "# Then we standarize the values dictated by the condition, to the new scale\n",
    "ASD_phenotypic_filtered['FIQ'] = np.where(condition, \n",
    "                        (ASD_phenotypic_filtered['FIQ'] - 50) / (160 - 50) * (170 - 30) + 30, \n",
    "                        ASD_phenotypic_filtered['FIQ'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For VIQ, the score scale is between 31-169 if the test taken was \"DAS\", \n",
    "#between 36-164 if the test taken was \"STANFORD\",\n",
    " #between 40-160 if the test taken was \"PPVT\",  otherwise is 50-160.\n",
    "#We will unify all the data to the larger scale, i.e. 31-169\n",
    "\n",
    "for i in range(len(ASD_phenotypic_filtered['VIQ'])):\n",
    "    test_type = ASD_phenotypic_filtered['FIQ_TEST_TYPE'][i]\n",
    "    current_value = ASD_phenotypic_filtered['VIQ'][i]\n",
    "    if (test_type != ('DAS' or 'STANFORD' or 'PPVT')) and (50 <= current_value <= 160):\n",
    "        ASD_phenotypic_filtered.loc[i, 'VIQ'] = (current_value - 50) / (160 - 50) * (169 - 31) + 31\n",
    "    elif (test_type != ('DAS' or 'STANFORD')) and (40 <= current_value <= 160):\n",
    "        ASD_phenotypic_filtered.loc[i, 'VIQ'] = (current_value - 40) / (160 - 40) * (169 - 31) + 31\n",
    "    elif (test_type != 'DAS') and (36 <= current_value <= 164):\n",
    "        ASD_phenotypic_filtered.loc[i, 'VIQ'] = (current_value - 36) / (164 - 36) * (169 - 31) + 31\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For PIQ, the score scale is between 31-166 if the test taken was \"DAS\", \n",
    "#between 36-164 if the test taken was \"STANFORD\",\n",
    " #between 50-160 if the test taken was \"RAVENS\",  otherwise is 53-160.\n",
    "#We will unify all the data to the larger scale, i.e. 31-169\n",
    "\n",
    "for i in range(len(ASD_phenotypic_filtered['PIQ'])):\n",
    "    test_type = ASD_phenotypic_filtered['FIQ_TEST_TYPE'][i]\n",
    "    current_value = ASD_phenotypic_filtered['PIQ'][i]\n",
    "    if (test_type != ('DAS' or 'STANFORD' or 'RAVENS')) and (53 <= current_value <= 160):\n",
    "        ASD_phenotypic_filtered.loc[i, 'PIQ'] = (current_value - 53) / (160 - 53) * (166 - 31) + 31\n",
    "    elif (test_type != ('DAS' or 'STANFORD')) and (50 <= current_value <= 160):\n",
    "        ASD_phenotypic_filtered.loc[i, 'PIQ'] = (current_value - 50) / (160 - 50) * (166 - 31) + 31\n",
    "    elif (test_type != 'DAS') and (36 <= current_value <= 164):\n",
    "        ASD_phenotypic_filtered.loc[i, 'PIQ'] = (current_value - 36) / (164 - 36) * (166 - 31) + 31\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test scores filling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided that to fill the missing values of the test subministred\n",
    "it should be good to rely on the standard score achieved by the mean\n",
    "of the global population (if the statistics are available in the literature) or the cutoff for the diagnostic of ASD,\n",
    "otherwise we will use the mean extracted from our dataset.\n",
    "\n",
    "So for the features \"FIQ\", \"VIQ\", \"PIQ\", \"ADOS_COMM\", \"ADOS_SOCIAL\", \"ADI_R_SOCIAL_TOTAL_A\", \"ADI_R_VERBAL_TOTAL_BV\", \"ADI_RRB_TOTAL_C\", \"SRS_RAW_TOTAL\" we will apply a custom function that checks if there is an available value in literature for the mundial mean, otherwise assign the mean of the feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of features that we want to fill\n",
    "test_score_fatures = [\"FIQ\", \"VIQ\", \"PIQ\", \"ADOS_COMM\", \"ADOS_SOCIAL\", \"ADI_R_SOCIAL_TOTAL_A\", \"ADI_R_VERBAL_TOTAL_BV\", \"ADI_RRB_TOTAL_C\", \"SRS_RAW_TOTAL\"]\n",
    "\n",
    "#function to fill with the global mean or the data feature mean\n",
    "def test_score_fill (feature_value, feature_name, feature_mean):\n",
    "    # We create a dictionary to store the literature mean scores\n",
    "    literature_scores = {\n",
    "    \"FIQ\": 97.34, # EEUU mean score retrieved from https://worldpopulationreview.com/country-rankings/average-iq-by-country\n",
    "    \"VIQ\": 97.34, # EEUU mean score retrieved from https://worldpopulationreview.com/country-rankings/average-iq-by-country\n",
    "    \"PIQ\": 97.34, # EEUU mean score retrieved from https://worldpopulationreview.com/country-rankings/average-iq-by-country\n",
    "    \"ADOS_COMM\": 3.0, # autism cutoff retrieved from https://www.researchgate.net/figure/ADOS-maximum-score-and-cut-off-points-for-ASD-15_tbl1_361212648\n",
    "    \"ADOS_SOCIAL\": 6.0, # autism cutoff retrieved from https://www.researchgate.net/figure/ADOS-maximum-score-and-cut-off-points-for-ASD-15_tbl1_361212648\n",
    "    \"ADI_R_SOCIAL_TOTAL_A\": 10.0, # autism cutoff retrieved from https://www.researchgate.net/figure/Summary-statistics-for-ADI-R-domain-scores_tbl4_6709395 \n",
    "    \"ADI_R_VERBAL_TOTAL_BV\": 8.0, # autism cutoff retrieved from https://www.researchgate.net/figure/Summary-statistics-for-ADI-R-domain-scores_tbl4_6709395\n",
    "    \"ADI_RRB_TOTAL_C\": 3.0, # autism cutoff retrieved from https://www.researchgate.net/figure/Summary-statistics-for-ADI-R-domain-scores_tbl4_6709395\n",
    "    \"SRS_RAW_TOTAL\": 61.0, # autism cutoff retrieved from https://www.researchgate.net/figure/The-Social-Responsiveness-Scale-Second-Edition-Cut-Off-Points_tbl3_378881666\n",
    "    }\n",
    "\n",
    "    # Then we check which feature we obtained to decide if replace\n",
    "    # using the value in the dictionary ot directly the mean of the data\n",
    "    if pd.isna(feature_value):\n",
    "\n",
    "        if feature_name in literature_scores:\n",
    "            return literature_scores[feature_name]\n",
    "        else:\n",
    "            return feature_mean\n",
    "    else:\n",
    "\n",
    "        return feature_value\n",
    "\n",
    "#loop for filling the features   \n",
    "for feature_name in test_score_fatures:\n",
    "    feature_mean = ASD_phenotypic_original[feature_name].mean()\n",
    "    ASD_phenotypic_filtered[feature_name] = ASD_phenotypic_filtered[feature_name].apply(test_score_fill, args=(feature_name, feature_mean))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADI_R_RSRCH_RELIABLE and ADOS_RSRCH_RELIABLE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to replace the missing values for the reliability of the subministration of the tests (indicates if it was taken by trained professionals or not) by the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this aim we can simply reuse the function test_score_fill,\n",
    "#giving the mode instead of the mean as a parameter.\n",
    "\n",
    "feature_mode = ASD_phenotypic_original[\"ADI_R_RSRCH_RELIABLE\"].mode()\n",
    "ASD_phenotypic_filtered[\"ADI_R_RSRCH_RELIABLE\"] = ASD_phenotypic_filtered[\"ADI_R_RSRCH_RELIABLE\"].apply(test_score_fill, args=(feature_name, feature_mode))\n",
    "\n",
    "feature_mode = ASD_phenotypic_original[\"ADOS_RSRCH_RELIABLE\"].mode()\n",
    "ASD_phenotypic_filtered[\"ADOS_RSRCH_RELIABLE\"] = ASD_phenotypic_filtered[\"ADOS_RSRCH_RELIABLE\"].apply(test_score_fill, args=(feature_name, feature_mode))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADOS_TOTAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature \"ADOS_TOTAL\" is simply the sum of the scores obtained by \"ADOS_COMM\" and \"ADOS_SOCIAL\", so we can fill the missing values using the values of those features now that they are complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for i in range (0, len(ASD_phenotypic_filtered[\"ADOS_TOTAL\"])):\n",
    "    ados_comm = ASD_phenotypic_filtered[\"ADOS_COMM\"][i]\n",
    "    ados_social = ASD_phenotypic_filtered[\"ADOS_SOCIAL\"][i]\n",
    "    ASD_phenotypic_filtered[\"ADOS_TOTAL\"][i] = ados_comm + ados_social'''\n",
    "\n",
    "ADOS_total = ASD_phenotypic_filtered[\"ADOS_COMM\"] + ASD_phenotypic_filtered[\"ADOS_SOCIAL\"]\n",
    "\n",
    "ASD_phenotypic_filtered.loc[:, \"ADOS_TOTAL\"] = ADOS_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current_Med_Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to proceed with the same logic used for IQ_TEST_TYPE. We make a comparison with another linked feature: CURRENT_MED_STATUS. If there is a value, so we fill missing value with 1, if there is anything we insert the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in ASD_phenotypic_filtered.iterrows():\n",
    "    # Ottieni l'indice della riga corrente nel DataFrame originale\n",
    "    original_index = row.name\n",
    "    \n",
    "    # Accedi ai valori corrispondenti di MEDICATION_NAME nel DataFrame originale\n",
    "    medication_name_value = ASD_phenotypic_original.at[original_index, 'MEDICATION_NAME']\n",
    "    \n",
    "    if pd.isnull(medication_name_value) and pd.isnull(row['CURRENT_MED_STATUS']):\n",
    "        # Se entrambi i valori in 'MEDICATION_NAME' e 'CURRENT_MED_STATUS' sono mancanti\n",
    "        # Riempire 'CURRENT_MED_STATUS' con la moda di 'CURRENT_MED_STATUS'\n",
    "        mode_current_med_status = ASD_phenotypic_filtered['CURRENT_MED_STATUS'].mode()[0]\n",
    "        ASD_phenotypic_filtered.at[index, 'CURRENT_MED_STATUS'] = mode_current_med_status\n",
    "    elif pd.notnull(medication_name_value) and pd.isnull(row['CURRENT_MED_STATUS']):\n",
    "        # Se il valore in 'MEDICATION_NAME' è presente e il valore in 'CURRENT_MED_STATUS' è mancante\n",
    "        # Imposta 'CURRENT_MED_STATUS' su 1\n",
    "        ASD_phenotypic_filtered.at[index, 'CURRENT_MED_STATUS'] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADOS_MODULE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I vari moduli esistenti sono per fascia d'età:\n",
    "- Module 1 | 12-30 months\n",
    "- Module 2 | 2 years + 6 months - 5 years\n",
    "- Module 3 | 5 years - 8 years + 11 months\n",
    "- Module 4 | 9 years - adulthood\n",
    "\n",
    "Since this, we apply the following logic:\n",
    "comparison between this feature and AGE_AT_SCAN. If there is a value in AGE_AT_SCAN, we control it and fill the corresponding missing value in ADOS_MODULE with the correct one. Otherwise, we fill with NOT_AVAILABLE category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteriamo su ogni riga del DataFrame\n",
    "for index, row in ASD_phenotypic_filtered.iterrows():\n",
    "    # Controlliamo se il valore in 'AGE_AT_SCAN' è presente\n",
    "    if pd.notnull(row['AGE_AT_SCAN']):\n",
    "        age_at_scan = row['AGE_AT_SCAN']\n",
    "        # Determiniamo il modulo corretto in base all'età\n",
    "        if age_at_scan >= 9:\n",
    "            ados_module = 4\n",
    "        elif age_at_scan >= 5:\n",
    "            ados_module = 3\n",
    "        elif age_at_scan >= 2.5:\n",
    "            ados_module = 2\n",
    "        else:\n",
    "            ados_module = 1\n",
    "        # Assegniamo il valore del modulo calcolato a 'ADOS_MODULE'\n",
    "        ASD_phenotypic_filtered.at[index, 'ADOS_MODULE'] = ados_module\n",
    "    else:\n",
    "        # Se 'AGE_AT_SCAN' è mancante, impostiamo 'ADOS_MODULE' su 'NOT_AVAILABLE'\n",
    "        ASD_phenotypic_filtered.at[index, 'ADOS_MODULE'] = 'NOT_AVAILABLE'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HANDEDNESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that we have two features that indicates the handedness of the subject. As the information that they carry should be the same, we decided to unify them in a unique score, in the following manner:\n",
    "\n",
    "As HANDEDNESS_CATEGORY has less missing values, we will HANDEDNESS_SCORE to extract more information.\n",
    "If a value is present, we will fi it with:\n",
    "- R if handedness_score > 0\n",
    "- L if handedness_score < 0\n",
    "- AMBI if handedness_score = 0\n",
    "Else, if the values is missed in both categories, we will fill it with the mode of HANDEDNESS_CATEGORY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteriamo su ogni riga del DataFrame originale\n",
    "for index, row in ASD_phenotypic_filtered.iterrows():\n",
    "    # Controlliamo se il valore in 'HANDEDNESS_SCORES' è presente\n",
    "    if pd.notnull(row['HANDEDNESS_SCORES']):\n",
    "        handness_score = row['HANDEDNESS_SCORES']\n",
    "        # Assegniamo il valore di 'handness_category' in base al valore di 'handness_score'\n",
    "        if handness_score > 0:\n",
    "            handness_category = 'R'\n",
    "        elif handness_score < 0:\n",
    "            handness_category = 'L'\n",
    "        else:\n",
    "            handness_category = 'AMBI'\n",
    "        # Assegniamo il valore di 'handness_category' al DataFrame filtrato\n",
    "        ASD_phenotypic_filtered.at[index, 'HANDEDNESS_CATEGORY'] = handness_category\n",
    "    else:\n",
    "        # Se 'handness_score' è mancante, controlliamo se 'handness_category' è mancante\n",
    "        if pd.isnull(ASD_phenotypic_filtered.at[index, 'HANDEDNESS_CATEGORY']):\n",
    "            # Riempire 'handness_category' con la moda di 'handness_category'\n",
    "            mode_handness_category = ASD_phenotypic_filtered['HANDEDNESS_CATEGORY'].mode()[0]\n",
    "            ASD_phenotypic_filtered.at[index, 'HANDEDNESS_CATEGORY'] = mode_handness_category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can drop HANDEDNESS_SCORES from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_filtered = ASD_phenotypic_filtered.drop(columns=['HANDEDNESS_SCORES'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that if we display the information of the dataset, we have no longer presence of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ASD_phenotypic_filtered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to proceed with a Correlation Matrix to exclude some features from our analysis we need to transform categorical features into numerical ones. \n",
    "Since the absence of internal order and not a huge quantity of different unique categories inside each feature, we select one-hot encoding technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizza la funzione get_dummies() di pandas per eseguire il one-hot encoding\n",
    "ASD_phenotypic_encoded = pd.get_dummies(ASD_phenotypic_filtered, columns=categorical_columns_filtered)\n",
    "\n",
    "# Ora ASD_phenotypic_encoded contiene le colonne originali numeriche insieme alle nuove colonne one-hot encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualizza l'intero contenuto del DataFrame\n",
    "print(ASD_phenotypic_encoded.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since didfferent scales of numerical features, we need to normalize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona solo le colonne numeriche e rimuovi le righe con valori mancanti\n",
    "numeric = ASD_phenotypic_filtered.select_dtypes(include=['float64', 'int64']).dropna()\n",
    "\n",
    "# Normalizza le features numeriche utilizzando la normalizzazione min-max\n",
    "scaler = MinMaxScaler()\n",
    "numeric_normalized = pd.DataFrame(scaler.fit_transform(numeric), columns=numeric.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiungi le colonne numeriche normalizzate al DataFrame filtered\n",
    "ASD_phenotypic_normalized = ASD_phenotypic_filtered.copy()\n",
    "ASD_phenotypic_normalized[numeric_normalized.columns] = numeric_normalized\n",
    "\n",
    "# Ora filtered contiene le features numeriche normalizzate insieme alle altre colonne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRELATION ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform correlation analysis separatamente, per numeriche e categoriche così da eliminarne alcune. Poi o ANOVA TEST O BOX PLOT O CAPIAMO PER TROVARE EVENTUALE CORRELAZIONE TRA NUMERICHE E CATEGORICHE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''numeric_features = ASD_phenotypic_filtered.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calcola la correlation matrix\n",
    "correlation_matrix = numeric_features.corr()\n",
    "\n",
    "# Visualizza la correlation matrix\n",
    "print(correlation_matrix)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORRELATION MATRIX\n",
    "# Calcola la correlazione tra le features normalizzate\n",
    "correlation_matrix = numeric_normalized.corr()\n",
    "numeric_normalized.T\n",
    "f,ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(numeric_normalized.corr(), \n",
    "            annot=True, \n",
    "            linewidths=.5, \n",
    "            fmt= '.2f',\n",
    "            ax=ax,\n",
    "            vmin=-1, \n",
    "            vmax=1,\n",
    "            cmap = \"coolwarm\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Eliminazione numeriche correlate\n",
    "-Correlazione per categoriche (Chi square o altro)\n",
    "-Eliminazione categoriche correlate\n",
    "-Confronto per correlazione tra numeriche e categoriche (box plot o altro)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
