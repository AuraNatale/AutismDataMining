{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "# from our documents\n",
    "import OurFunctions as of\n",
    "\n",
    "# from Scikit Learn library\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, make_scorer, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.tree import plot_tree \n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "# from Imb Learn\n",
    "from imblearn.over_sampling import SMOTENC, SMOTE\n",
    "\n",
    "#seed for random processes\n",
    "seed = 42\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic = pd.read_csv(os.path.join('DataSets','Phenotypic Datasets','ASD_phenotypic_preprocessed.csv'))\n",
    "ASD_diagnosis = pd.read_csv(os.path.join('DataSets','Phenotypic Datasets','ASD_clinical.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (213, 8)\n",
      "Test set size: (92, 8)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "ASD_phenotypic = ASD_phenotypic.drop(columns=[\"SITE_ID\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(ASD_phenotypic, ASD_diagnosis['DX_GROUP'], test_size=0.3, random_state=42)\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = X_train.select_dtypes(include=['object']).columns\n",
    "categorical_features = categorical_columns.tolist()\n",
    "\n",
    "# Initializing SMOTE-NC \n",
    "sampler = SMOTENC(categorical_features=categorical_features, random_state=42)\n",
    "\n",
    "# Applying SMOTE-NC in order to generate new syntetic samples\n",
    "X_SMOTE, Y_SMOTE = sampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_pipeline(dataset, target, classifier, encoder = True, scaler = True, parameters_grid_search = None, cv = None, feature_selector=False,  parameters_feature_selector = None):\n",
    "\n",
    "    # Defining metrics to be used as scoring \n",
    "    scoring = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'precision': make_scorer(precision_score),\n",
    "        'recall': make_scorer(recall_score),\n",
    "        'f1_score': make_scorer(f1_score)\n",
    "    }\n",
    "\n",
    "    # Preprocess to make on the train data may include\n",
    "    # - normalization of the numerical columns\n",
    "    # - one hot encoding on the categorical columns\n",
    "    \n",
    "    categorical_columns = dataset.select_dtypes(include=['object']).columns\n",
    "\n",
    "    if not encoder: #only scaler\n",
    "        transformers = [('num', RobustScaler(), ~dataset.columns.isin(categorical_columns))]\n",
    "    elif not scaler: #only encoder\n",
    "        transformers = [('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)]\n",
    "    elif not encoder and not scaler:\n",
    "        transformers = []\n",
    "    else: # both scaler and encoder\n",
    "        transformers=[\n",
    "            ('num', RobustScaler(), ~dataset.columns.isin(categorical_columns)),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
    "        ]\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=transformers)\n",
    "\n",
    "    # set parameters per KNN case\n",
    "    if isinstance(classifier, KNeighborsClassifier):\n",
    "        parameter_type = 'classifier__n_neighbors'\n",
    "        if parameters_grid_search:\n",
    "            parameters = {parameter_type: parameters_grid_search}  # n_neighbors values to be explored \n",
    "        else:\n",
    "            parameters = {parameter_type: [3, 5, 7, 9, 11]} \n",
    "\n",
    "        feature_selector_type = SelectKBest(score_func=f_classif)\n",
    "        selector_parameter = 'feature_selection__k'\n",
    "        \n",
    "    # set parameters per RF case\n",
    "    if isinstance(classifier, RandomForestClassifier):\n",
    "        parameter_type = 'classifier__n_estimators'\n",
    "        if parameters_grid_search:\n",
    "            parameters = {parameter_type: parameters_grid_search}  \n",
    "        else:\n",
    "            parameters = {parameter_type: [10, 50, 200, 500, 1000]} \n",
    "\n",
    "        feature_selector_type = RFE(estimator=classifier)\n",
    "        selector_parameter = 'feature_selection__n_features_to_select'\n",
    "\n",
    "    # set parameters per LinearSVC case\n",
    "    if isinstance(classifier, CalibratedClassifierCV):\n",
    "        parameter_type = 'classifier__estimator__C'\n",
    "        if parameters_grid_search:\n",
    "            parameters = {parameter_type: parameters_grid_search}  \n",
    "        else:\n",
    "            parameters = {parameter_type: [1]}  \n",
    "\n",
    "        feature_selector_type = RFE(estimator=LinearSVC(dual=False, random_state=42))\n",
    "        selector_parameter = 'feature_selection__n_features_to_select'\n",
    "\n",
    "    \n",
    "    if feature_selector: # in case feature selection is required\n",
    "        \n",
    "        sample_transformed = preprocessor.fit_transform(dataset)\n",
    "        n_total_features = sample_transformed.shape[1]\n",
    "        print(\"Total quantity of features after one hot encoding :\" + str(n_total_features))\n",
    "        \n",
    "        # Pipeline with feature selector\n",
    "        pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('feature_selection', feature_selector_type),\n",
    "        ('classifier', classifier)  \n",
    "        ])\n",
    "        if parameters_feature_selector:\n",
    "            parameters.update({selector_parameter: parameters_feature_selector})\n",
    "        else: \n",
    "            parameters.update({selector_parameter: list(range(1, n_total_features+1))})\n",
    "            \n",
    "    else:\n",
    "        # Pipeline without feature selector\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', classifier),\n",
    "            ])\n",
    "\n",
    "    # allows to change k of cross validation from the outside\n",
    "    if cv:\n",
    "        k_folds = cv\n",
    "    else:\n",
    "        k_folds = 5\n",
    "\n",
    "    # Creating GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv= KFold(n_splits=k_folds, shuffle = True, random_state = 42), scoring=scoring, refit='accuracy')\n",
    "\n",
    "    # Executing \n",
    "    grid_search.fit(dataset, target)\n",
    "\n",
    "    # Extraction of results\n",
    "\n",
    "    means_accuracy = grid_search.cv_results_['mean_test_accuracy']\n",
    "    stds_accuracy = grid_search.cv_results_['std_test_accuracy']\n",
    "    means_precision = grid_search.cv_results_['mean_test_precision']\n",
    "    means_recall = grid_search.cv_results_['mean_test_recall']\n",
    "    means_f1_score = grid_search.cv_results_['mean_test_f1_score']\n",
    "    params = grid_search.cv_results_['params']\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_parameter = [grid_search.best_params_[parameter_type]]\n",
    "    best_accuracy = grid_search.best_score_\n",
    "    best_f1_score = grid_search.cv_results_['mean_test_f1_score'][grid_search.best_index_]\n",
    "    best_scores = [best_accuracy, best_f1_score]\n",
    "\n",
    "    feature_names = []\n",
    "    for feature in best_model.named_steps['preprocessor'].get_feature_names_out():\n",
    "        feature_names.append(feature)\n",
    "    # Visualization of results\n",
    "\n",
    "    if not parameters_grid_search: #the parameter is not choose from the outside\n",
    "        print(\"Cross-validation results for each combination of hyperparameters:\")\n",
    "        for mean_acc, std_acc, mean_prec, mean_rec, mean_f1, params in zip(means_accuracy, stds_accuracy, means_precision, means_recall, means_f1_score, params):\n",
    "            print(f\"Parameters: {params}, Accuracy: {mean_acc:.3f} (Â±{std_acc:.3f}), Precision: {mean_prec:.3f}, Recall: {mean_rec:.3f}, F1-score: {mean_f1:.3f}\")\n",
    "\n",
    "        print(\"\\nBest parameter founded:\")\n",
    "        print(best_parameter)\n",
    "        print(\"\\nThe scores achieved are:\")\n",
    "\n",
    "    print(\"Accuracy:\", best_accuracy)\n",
    "    print(\"F1-score:\", best_f1_score)\n",
    "\n",
    "    if feature_selector:\n",
    "        # Get the support mask and selected feature names from the preprocessed data\n",
    "        feature_names = best_model.named_steps['preprocessor'].get_feature_names_out()\n",
    "        selected_mask = best_model.named_steps['feature_selection'].get_support()\n",
    "        selected_features = []\n",
    "        for feature in feature_names[selected_mask]:\n",
    "            selected_features.append(feature)\n",
    "\n",
    "        print(\"\\nSelected features are:\")\n",
    "        print(f\"Number of selected features: {len(selected_features)}\")\n",
    "        print(\"Selected features:\", selected_features)\n",
    "\n",
    "        non_selected_mask = ~selected_mask\n",
    "        non_selected_features = feature_names[non_selected_mask]\n",
    "\n",
    "        print(\"\\nNon selected features are:\")\n",
    "        print(f\"Number of non selected features: {len(non_selected_features)}\")\n",
    "        print(\"Selected features:\", non_selected_features)\n",
    "\n",
    "        best_parameter.append(grid_search.best_params_[selector_parameter])\n",
    "\n",
    "        return best_model, best_parameter, best_scores, selected_features\n",
    "        \n",
    "    return best_model, best_parameter, best_scores, feature_names\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest Classifier\n",
    "- 50 trees\n",
    "- No outlier remotion\n",
    "- No feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9814903846153846\n",
      "F1-score: 0.9817209205888451\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(random_state=42)\n",
    "rf_model, rf_parameter, rf_scores, _ = general_pipeline(X_SMOTE, Y_SMOTE, classifier, parameters_grid_search = [50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valutazione del modello sui dati di test:\n",
      "Accuratezza: 0.978\n",
      "Precisione: 1.000\n",
      "Richiamo: 0.970\n",
      "F1-score: 0.985\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Model on Test Data \n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Prints and stores scores of the model on testing set\n",
    "accuracy, precision, recall, f1 = of.evaluation_test_scores(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " More accurate parameter:\n",
      "50\n",
      "Accuration with best parameter: 0.9485777496839445\n",
      "\n",
      "Selected features are:\n",
      "Number of selected features: 16\n",
      "Selected features: ['num__AGE_AT_SCAN' 'num__SEX' 'num__FIQ' 'num__VIQ' 'num__PIQ'\n",
      " 'num__ADI_R_VERBAL_TOTAL_BV' 'num__ADOS_TOTAL' 'cat__FIQ_TEST_TYPE_DAS'\n",
      " 'cat__FIQ_TEST_TYPE_WASI' 'cat__FIQ_TEST_TYPE_WISC'\n",
      " 'cat__VIQ_TEST_TYPE_PPVT' 'cat__VIQ_TEST_TYPE_WASI'\n",
      " 'cat__VIQ_TEST_TYPE_WISC' 'cat__PIQ_TEST_TYPE_Ravens'\n",
      " 'cat__PIQ_TEST_TYPE_WASI' 'cat__PIQ_TEST_TYPE_WISC']\n",
      "\n",
      "Non selected features are:\n",
      "Number of non selected features: 10\n",
      "Selected features: ['cat__FIQ_TEST_TYPE_WAIS' 'cat__VIQ_TEST_TYPE_DAS'\n",
      " 'cat__VIQ_TEST_TYPE_Stanford' 'cat__VIQ_TEST_TYPE_WAIS'\n",
      " 'cat__VIQ_TEST_TYPE_ppvt' 'cat__PIQ_TEST_TYPE_DAS'\n",
      " 'cat__PIQ_TEST_TYPE_Ravens  ' 'cat__PIQ_TEST_TYPE_Stanford'\n",
      " 'cat__PIQ_TEST_TYPE_WAIS' 'cat__PIQ_TEST_TYPE_ravens']\n"
     ]
    }
   ],
   "source": [
    "fs_RF, fs_RF_parameter, fs_RF_accuracy, fs_RF_selected_features = general_pipeline(X_SMOTE, Y_SMOTE, classifier, parameters_grid_search = [50], feature_selector=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valutazione del modello sui dati di test:\n",
      "Accuratezza: 0.965\n",
      "Precisione: 0.952\n",
      "Richiamo: 0.992\n",
      "F1-score: 0.972\n"
     ]
    }
   ],
   "source": [
    "# Valutazione del modello sui dati di test\n",
    "y_pred = fs_RF.predict(X_test)\n",
    "\n",
    "# Calcolo delle metriche sui dati di test\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nValutazione del modello sui dati di test:\")\n",
    "print(f\"Accuratezza: {accuracy:.3f}\")\n",
    "print(f\"Precisione: {precision:.3f}\")\n",
    "print(f\"Richiamo: {recall:.3f}\")\n",
    "print(f\"F1-score: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detector(dataset, diagnosis, contamination_factor):\n",
    "    dataset_outliers = dataset.select_dtypes(include=[np.number])\n",
    "    X = dataset_outliers.values\n",
    "\n",
    "    # Initialize Local Outlier Factor\n",
    "    lof = LocalOutlierFactor(n_neighbors=10, contamination=contamination_factor)  # Adjust parameters as needed\n",
    "    '''n_neighbors | if too small: model sensible to noise and random outliers\n",
    "                 if too large: diculties in local outliers detection, in particular if in absence oa a uniform distribution\n",
    "       contamination | data portion expected as outliers'''\n",
    "    # Fit the model and predict outliers\n",
    "    outliers = lof.fit_predict(X)\n",
    "\n",
    "    # Print number of detected outliers\n",
    "    print(f\"Number of outliers detected: {np.sum(outliers == -1)}\")\n",
    "\n",
    "    # outliers == -1 indicates outliers, 1 indicates inliers\n",
    "    dataset_outliers['outlier'] = outliers\n",
    "\n",
    "    outlier_subjects = dataset_outliers[dataset_outliers['outlier'] == -1]\n",
    "\n",
    "    pd.set_option('display.max_columns', None); outlier_subjects.T\n",
    "\n",
    "    dataset_without_outliers = dataset[dataset_outliers['outlier'] == 1]\n",
    "         \n",
    "    diagnosis_without_outliers = diagnosis[dataset_outliers['outlier'] == 1]\n",
    "\n",
    "    return dataset_without_outliers, diagnosis_without_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers detected: 6\n"
     ]
    }
   ],
   "source": [
    "ASD_phenotypic_without_outliers, ASD_diagnosis_without_outliers = outlier_detector(ASD_phenotypic, ASD_clinical, 0.008)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ASD_phenotypic_without_outliers, ASD_diagnosis_without_outliers['DX_GROUP'], test_size=0.3, random_state=42)\n",
    "\n",
    "categorical_columns = X_train.select_dtypes(include=['object','category']).columns\n",
    "categorical_features = categorical_columns.tolist()\n",
    "\n",
    "# Inizializza l'oggetto SMOTE-NC specificando gli indici delle colonne categoriche\n",
    "sampler = SMOTENC(categorical_features=categorical_features, random_state=42)\n",
    "\n",
    "# Applica SMOTE-NC per generare nuovi esempi sintetici\n",
    "X_SMOTE, Y_SMOTE = sampler.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " More accurate parameter:\n",
      "50\n",
      "Accuration with best parameter: 0.9434361968306921\n",
      "\n",
      "Selected features are:\n",
      "Number of selected features: 16\n",
      "Selected features: ['num__AGE_AT_SCAN' 'num__SEX' 'num__FIQ' 'num__VIQ' 'num__PIQ'\n",
      " 'num__ADI_R_VERBAL_TOTAL_BV' 'num__ADOS_TOTAL' 'cat__FIQ_TEST_TYPE_DAS'\n",
      " 'cat__FIQ_TEST_TYPE_WASI' 'cat__FIQ_TEST_TYPE_WISC'\n",
      " 'cat__VIQ_TEST_TYPE_DAS' 'cat__VIQ_TEST_TYPE_PPVT'\n",
      " 'cat__VIQ_TEST_TYPE_WASI' 'cat__VIQ_TEST_TYPE_WISC'\n",
      " 'cat__PIQ_TEST_TYPE_Ravens' 'cat__PIQ_TEST_TYPE_WASI']\n",
      "\n",
      "Non selected features are:\n",
      "Number of non selected features: 8\n",
      "Selected features: ['cat__FIQ_TEST_TYPE_WAIS' 'cat__VIQ_TEST_TYPE_WAIS'\n",
      " 'cat__VIQ_TEST_TYPE_ppvt' 'cat__PIQ_TEST_TYPE_DAS'\n",
      " 'cat__PIQ_TEST_TYPE_Ravens  ' 'cat__PIQ_TEST_TYPE_WAIS'\n",
      " 'cat__PIQ_TEST_TYPE_WISC' 'cat__PIQ_TEST_TYPE_ravens']\n"
     ]
    }
   ],
   "source": [
    "od_RF, od_RF_parameter, od_RF_accuracy, od_RF_selected_features = general_pipeline(X_SMOTE, Y_SMOTE, classifier, parameters_grid_search = [50], feature_selector=True, parameters_feature_selector=[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valutazione del modello sui dati di test:\n",
      "Accuratezza: 0.950\n",
      "Precisione: 0.945\n",
      "Richiamo: 0.976\n",
      "F1-score: 0.960\n"
     ]
    }
   ],
   "source": [
    "# Valutazione del modello sui dati di test\n",
    "y_pred = od_RF.predict(X_test)\n",
    "\n",
    "# Calcolo delle metriche sui dati di test\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nValutazione del modello sui dati di test:\")\n",
    "print(f\"Accuratezza: {accuracy:.3f}\")\n",
    "print(f\"Precisione: {precision:.3f}\")\n",
    "print(f\"Richiamo: {recall:.3f}\")\n",
    "print(f\"F1-score: {f1:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
