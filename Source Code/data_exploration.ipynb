{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents | ASD DATA \n",
    "\n",
    "- [The BREAST-CANCER dataset](#The-BREAST-CANCER-dataset):\n",
    "    - [Load the dataset](#Load-the-Dataset)\n",
    "    - [Explore the dataset: Descriptive statistics](#Explore-the-dataset:-Descriptive-statistics)\n",
    "    - [Explore the dataset: Visualization](#Explore-the-dataset:-Visualization)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The entire project has been based on the following study [Investigating the Correspondence of Clinical  Diagnostic Grouping With Underlying Neurobiological and Phenotypic Clusters Using Unsupervised Machine Learning](https://doi.org/10.1016/j.dib.2018.01.080).\n",
    "\n",
    "The work focuses on two different pathologies in brain disorders: ASD and ADHD\n",
    "\n",
    "## The ASD dataset\n",
    "\n",
    "available at [ABIDE I database](https://fcon_1000.projects.nitrc.org/indi/abide/abide_I.html).\n",
    "\n",
    "\n",
    "This is .......\n",
    " \n",
    "This data set includes 286 intances (201 of one class, 85 of another class).  The instances are described by 9 attributes, some of which are ordinal and some are nominal.\n",
    " \n",
    "Attribute information\n",
    "\n",
    "| column | values |\n",
    "| --- | --- |\n",
    "| Class | no-recurrence-events, recurrence-events |\n",
    "| age | 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99|\n",
    "| menopause | lt40, ge40, premeno|\n",
    "| tumor-size | 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59|\n",
    "| inv-nodes | 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26, 27-29, 30-32, 33-35, 36-39|\n",
    "| node-caps | yes, no|\n",
    "| deg-malig | 1, 2, 3|\n",
    "| breast | left, right|\n",
    "| breast-quad | left-up, left-low, right-up, right-low, central|\n",
    "| irradiat | yes, no|\n",
    " \n",
    "There are 9 Missing Attribute Values (denoted by \"?\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt #for the plots\n",
    "import seaborn as sns \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic = pd.read_csv(os.path.join('DataSets','Phenotypic Datasets','ASD','ASD_phenotypic.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>DSM_IV_TR</th>\n",
       "      <th>AGE_AT_SCAN</th>\n",
       "      <th>SEX</th>\n",
       "      <th>HANDEDNESS_CATEGORY</th>\n",
       "      <th>HANDEDNESS_SCORES</th>\n",
       "      <th>FIQ</th>\n",
       "      <th>VIQ</th>\n",
       "      <th>...</th>\n",
       "      <th>WISC_IV_BLK_DSN_SCALED</th>\n",
       "      <th>WISC_IV_PIC_CON_SCALED</th>\n",
       "      <th>WISC_IV_MATRIX_SCALED</th>\n",
       "      <th>WISC_IV_DIGIT_SPAN_SCALED</th>\n",
       "      <th>WISC_IV_LET_NUM_SCALED</th>\n",
       "      <th>WISC_IV_CODING_SCALED</th>\n",
       "      <th>WISC_IV_SYM_SCALED</th>\n",
       "      <th>EYE_STATUS_AT_SCAN</th>\n",
       "      <th>AGE_AT_MPRAGE</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51456</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>55.40</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51457</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22.90</td>\n",
       "      <td>1</td>\n",
       "      <td>Ambi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51458</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.20</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51459</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.80</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51460</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.60</td>\n",
       "      <td>2</td>\n",
       "      <td>Ambi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>YALE</td>\n",
       "      <td>50624</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11.08</td>\n",
       "      <td>2</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>YALE</td>\n",
       "      <td>50625</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>YALE</td>\n",
       "      <td>50626</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11.08</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>YALE</td>\n",
       "      <td>50627</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.50</td>\n",
       "      <td>2</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>YALE</td>\n",
       "      <td>50628</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14.42</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1112 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SITE_ID  SUB_ID  DX_GROUP  DSM_IV_TR  AGE_AT_SCAN  SEX  \\\n",
       "0     CALTECH   51456         1          4        55.40    1   \n",
       "1     CALTECH   51457         1          4        22.90    1   \n",
       "2     CALTECH   51458         1          1        39.20    1   \n",
       "3     CALTECH   51459         1          1        22.80    1   \n",
       "4     CALTECH   51460         1          1        34.60    2   \n",
       "...       ...     ...       ...        ...          ...  ...   \n",
       "1107     YALE   50624         1          3        11.08    2   \n",
       "1108     YALE   50625         1          3         7.00    1   \n",
       "1109     YALE   50626         1          3        11.08    1   \n",
       "1110     YALE   50627         1          3         9.50    2   \n",
       "1111     YALE   50628         1          3        14.42    1   \n",
       "\n",
       "     HANDEDNESS_CATEGORY  HANDEDNESS_SCORES    FIQ    VIQ  ...  \\\n",
       "0                      R                NaN  126.0  118.0  ...   \n",
       "1                   Ambi                NaN  107.0  119.0  ...   \n",
       "2                      R                NaN   93.0   80.0  ...   \n",
       "3                      R                NaN  106.0   94.0  ...   \n",
       "4                   Ambi                NaN  133.0  135.0  ...   \n",
       "...                  ...                ...    ...    ...  ...   \n",
       "1107                   R                NaN   90.0   91.0  ...   \n",
       "1108                   L                NaN   99.0   90.0  ...   \n",
       "1109                   L                NaN   61.0   66.0  ...   \n",
       "1110                   R                NaN   88.0  103.0  ...   \n",
       "1111                   R                NaN   77.0   72.0  ...   \n",
       "\n",
       "      WISC_IV_BLK_DSN_SCALED WISC_IV_PIC_CON_SCALED WISC_IV_MATRIX_SCALED  \\\n",
       "0                        NaN                    NaN                   NaN   \n",
       "1                        NaN                    NaN                   NaN   \n",
       "2                        NaN                    NaN                   NaN   \n",
       "3                        NaN                    NaN                   NaN   \n",
       "4                        NaN                    NaN                   NaN   \n",
       "...                      ...                    ...                   ...   \n",
       "1107                     NaN                    NaN                   NaN   \n",
       "1108                     NaN                    NaN                   NaN   \n",
       "1109                     NaN                    NaN                   NaN   \n",
       "1110                     NaN                    NaN                   NaN   \n",
       "1111                     NaN                    NaN                   NaN   \n",
       "\n",
       "     WISC_IV_DIGIT_SPAN_SCALED  WISC_IV_LET_NUM_SCALED  WISC_IV_CODING_SCALED  \\\n",
       "0                          NaN                     NaN                    NaN   \n",
       "1                          NaN                     NaN                    NaN   \n",
       "2                          NaN                     NaN                    NaN   \n",
       "3                          NaN                     NaN                    NaN   \n",
       "4                          NaN                     NaN                    NaN   \n",
       "...                        ...                     ...                    ...   \n",
       "1107                       NaN                     NaN                    NaN   \n",
       "1108                       NaN                     NaN                    NaN   \n",
       "1109                       NaN                     NaN                    NaN   \n",
       "1110                       NaN                     NaN                    NaN   \n",
       "1111                       NaN                     NaN                    NaN   \n",
       "\n",
       "      WISC_IV_SYM_SCALED  EYE_STATUS_AT_SCAN  AGE_AT_MPRAGE  BMI  \n",
       "0                    NaN                   2            NaN  NaN  \n",
       "1                    NaN                   2            NaN  NaN  \n",
       "2                    NaN                   2            NaN  NaN  \n",
       "3                    NaN                   2            NaN  NaN  \n",
       "4                    NaN                   2            NaN  NaN  \n",
       "...                  ...                 ...            ...  ...  \n",
       "1107                 NaN                   1            NaN  NaN  \n",
       "1108                 NaN                   1            NaN  NaN  \n",
       "1109                 NaN                   1            NaN  NaN  \n",
       "1110                 NaN                   1            NaN  NaN  \n",
       "1111                 NaN                   1            NaN  NaN  \n",
       "\n",
       "[1112 rows x 74 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualizziamo, non completamente, il nostro dataset\n",
    "#e otteniamone la dimensione: prima info utile\n",
    "ASD_phenotypic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>DSM_IV_TR</th>\n",
       "      <th>AGE_AT_SCAN</th>\n",
       "      <th>SEX</th>\n",
       "      <th>HANDEDNESS_CATEGORY</th>\n",
       "      <th>HANDEDNESS_SCORES</th>\n",
       "      <th>FIQ</th>\n",
       "      <th>VIQ</th>\n",
       "      <th>...</th>\n",
       "      <th>WISC_IV_BLK_DSN_SCALED</th>\n",
       "      <th>WISC_IV_PIC_CON_SCALED</th>\n",
       "      <th>WISC_IV_MATRIX_SCALED</th>\n",
       "      <th>WISC_IV_DIGIT_SPAN_SCALED</th>\n",
       "      <th>WISC_IV_LET_NUM_SCALED</th>\n",
       "      <th>WISC_IV_CODING_SCALED</th>\n",
       "      <th>WISC_IV_SYM_SCALED</th>\n",
       "      <th>EYE_STATUS_AT_SCAN</th>\n",
       "      <th>AGE_AT_MPRAGE</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51456</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>55.4</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51457</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>1</td>\n",
       "      <td>Ambi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51458</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.2</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51459</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.8</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALTECH</td>\n",
       "      <td>51460</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.6</td>\n",
       "      <td>2</td>\n",
       "      <td>Ambi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SITE_ID  SUB_ID  DX_GROUP  DSM_IV_TR  AGE_AT_SCAN  SEX HANDEDNESS_CATEGORY  \\\n",
       "0  CALTECH   51456         1          4         55.4    1                   R   \n",
       "1  CALTECH   51457         1          4         22.9    1                Ambi   \n",
       "2  CALTECH   51458         1          1         39.2    1                   R   \n",
       "3  CALTECH   51459         1          1         22.8    1                   R   \n",
       "4  CALTECH   51460         1          1         34.6    2                Ambi   \n",
       "\n",
       "   HANDEDNESS_SCORES    FIQ    VIQ  ...  WISC_IV_BLK_DSN_SCALED  \\\n",
       "0                NaN  126.0  118.0  ...                     NaN   \n",
       "1                NaN  107.0  119.0  ...                     NaN   \n",
       "2                NaN   93.0   80.0  ...                     NaN   \n",
       "3                NaN  106.0   94.0  ...                     NaN   \n",
       "4                NaN  133.0  135.0  ...                     NaN   \n",
       "\n",
       "  WISC_IV_PIC_CON_SCALED WISC_IV_MATRIX_SCALED WISC_IV_DIGIT_SPAN_SCALED  \\\n",
       "0                    NaN                   NaN                       NaN   \n",
       "1                    NaN                   NaN                       NaN   \n",
       "2                    NaN                   NaN                       NaN   \n",
       "3                    NaN                   NaN                       NaN   \n",
       "4                    NaN                   NaN                       NaN   \n",
       "\n",
       "   WISC_IV_LET_NUM_SCALED  WISC_IV_CODING_SCALED  WISC_IV_SYM_SCALED  \\\n",
       "0                     NaN                    NaN                 NaN   \n",
       "1                     NaN                    NaN                 NaN   \n",
       "2                     NaN                    NaN                 NaN   \n",
       "3                     NaN                    NaN                 NaN   \n",
       "4                     NaN                    NaN                 NaN   \n",
       "\n",
       "   EYE_STATUS_AT_SCAN  AGE_AT_MPRAGE  BMI  \n",
       "0                   2            NaN  NaN  \n",
       "1                   2            NaN  NaN  \n",
       "2                   2            NaN  NaN  \n",
       "3                   2            NaN  NaN  \n",
       "4                   2            NaN  NaN  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ASD_phenotypic.head() #in order to underline features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1112 entries, 0 to 1111\n",
      "Data columns (total 74 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   SITE_ID                          1112 non-null   object \n",
      " 1   SUB_ID                           1112 non-null   int64  \n",
      " 2   DX_GROUP                         1112 non-null   int64  \n",
      " 3   DSM_IV_TR                        1112 non-null   int64  \n",
      " 4   AGE_AT_SCAN                      1112 non-null   float64\n",
      " 5   SEX                              1112 non-null   int64  \n",
      " 6   HANDEDNESS_CATEGORY              797 non-null    object \n",
      " 7   HANDEDNESS_SCORES                370 non-null    float64\n",
      " 8   FIQ                              1077 non-null   float64\n",
      " 9   VIQ                              935 non-null    float64\n",
      " 10  PIQ                              953 non-null    float64\n",
      " 11  FIQ_TEST_TYPE                    947 non-null    object \n",
      " 12  VIQ_TEST_TYPE                    834 non-null    object \n",
      " 13  PIQ_TEST_TYPE                    853 non-null    object \n",
      " 14  ADI_R_SOCIAL_TOTAL_A             412 non-null    float64\n",
      " 15  ADI_R_VERBAL_TOTAL_BV            412 non-null    float64\n",
      " 16  ADI_RRB_TOTAL_C                  412 non-null    float64\n",
      " 17  ADI_R_ONSET_TOTAL_D              331 non-null    float64\n",
      " 18  ADI_R_RSRCH_RELIABLE             411 non-null    float64\n",
      " 19  ADOS_MODULE                      535 non-null    float64\n",
      " 20  ADOS_TOTAL                       442 non-null    float64\n",
      " 21  ADOS_COMM                        417 non-null    float64\n",
      " 22  ADOS_SOCIAL                      417 non-null    float64\n",
      " 23  ADOS_STEREO_BEHAV                378 non-null    float64\n",
      " 24  ADOS_RSRCH_RELIABLE              380 non-null    float64\n",
      " 25  ADOS_GOTHAM_SOCAFFECT            317 non-null    float64\n",
      " 26  ADOS_GOTHAM_RRB                  317 non-null    float64\n",
      " 27  ADOS_GOTHAM_TOTAL                317 non-null    float64\n",
      " 28  ADOS_GOTHAM_SEVERITY             317 non-null    float64\n",
      " 29  SRS_VERSION                      269 non-null    float64\n",
      " 30  SRS_RAW_TOTAL                    405 non-null    float64\n",
      " 31  SRS_AWARENESS                    64 non-null     float64\n",
      " 32  SRS_COGNITION                    64 non-null     float64\n",
      " 33  SRS_COMMUNICATION                64 non-null     float64\n",
      " 34  SRS_MOTIVATION                   64 non-null     float64\n",
      " 35  SRS_MANNERISMS                   64 non-null     float64\n",
      " 36  SCQ_TOTAL                        143 non-null    float64\n",
      " 37  AQ_TOTAL                         58 non-null     float64\n",
      " 38  COMORBIDITY                      64 non-null     object \n",
      " 39  CURRENT_MED_STATUS               817 non-null    object \n",
      " 40  MEDICATION_NAME                  157 non-null    object \n",
      " 41  OFF_STIMULANTS_AT_SCAN           141 non-null    float64\n",
      " 42  VINELAND_RECEPTIVE_V_SCALED      184 non-null    float64\n",
      " 43  VINELAND_EXPRESSIVE_V_SCALED     184 non-null    float64\n",
      " 44  VINELAND_WRITTEN_V_SCALED        184 non-null    float64\n",
      " 45  VINELAND_COMMUNICATION_STANDARD  184 non-null    float64\n",
      " 46  VINELAND_PERSONAL_V_SCALED       184 non-null    float64\n",
      " 47  VINELAND_DOMESTIC_V_SCALED       184 non-null    float64\n",
      " 48  VINELAND_COMMUNITY_V_SCALED      184 non-null    float64\n",
      " 49  VINELAND_DAILYLVNG_STANDARD      184 non-null    float64\n",
      " 50  VINELAND_INTERPERSONAL_V_SCALED  184 non-null    float64\n",
      " 51  VINELAND_PLAY_V_SCALED           184 non-null    float64\n",
      " 52  VINELAND_COPING_V_SCALED         184 non-null    float64\n",
      " 53  VINELAND_SOCIAL_STANDARD         184 non-null    float64\n",
      " 54  VINELAND_SUM_SCORES              184 non-null    float64\n",
      " 55  VINELAND_ABC_STANDARD            184 non-null    float64\n",
      " 56  VINELAND_INFORMANT               184 non-null    float64\n",
      " 57  WISC_IV_VCI                      55 non-null     float64\n",
      " 58  WISC_IV_PRI                      55 non-null     float64\n",
      " 59  WISC_IV_WMI                      55 non-null     float64\n",
      " 60  WISC_IV_PSI                      55 non-null     float64\n",
      " 61  WISC_IV_SIM_SCALED               55 non-null     float64\n",
      " 62  WISC_IV_VOCAB_SCALED             55 non-null     float64\n",
      " 63  WISC_IV_INFO_SCALED              55 non-null     float64\n",
      " 64  WISC_IV_BLK_DSN_SCALED           55 non-null     float64\n",
      " 65  WISC_IV_PIC_CON_SCALED           55 non-null     float64\n",
      " 66  WISC_IV_MATRIX_SCALED            55 non-null     float64\n",
      " 67  WISC_IV_DIGIT_SPAN_SCALED        55 non-null     float64\n",
      " 68  WISC_IV_LET_NUM_SCALED           55 non-null     float64\n",
      " 69  WISC_IV_CODING_SCALED            55 non-null     float64\n",
      " 70  WISC_IV_SYM_SCALED               55 non-null     float64\n",
      " 71  EYE_STATUS_AT_SCAN               1112 non-null   int64  \n",
      " 72  AGE_AT_MPRAGE                    101 non-null    float64\n",
      " 73  BMI                              214 non-null    float64\n",
      "dtypes: float64(61), int64(5), object(8)\n",
      "memory usage: 643.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#otteniamo le informazioni relative al dataset\n",
    "ASD_phenotypic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CATEGORICAL EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: SITE_ID\n",
      "CALTECH\n",
      "CMU\n",
      "KKI\n",
      "LEUVEN_1\n",
      "LEUVEN_2\n",
      "MAX_MUN\n",
      "NYU\n",
      "OHSU\n",
      "OLIN\n",
      "PITT\n",
      "SBL\n",
      "SDSU\n",
      "STANFORD\n",
      "TRINITY\n",
      "UCLA_1\n",
      "UCLA_2\n",
      "UM_1\n",
      "UM_2\n",
      "USM\n",
      "YALE\n",
      "\n",
      "Feature: HANDEDNESS_CATEGORY\n",
      "R\n",
      "Ambi\n",
      "L\n",
      "Mixed\n",
      "L->R\n",
      "nan\n",
      "-9999\n",
      "\n",
      "Feature: FIQ_TEST_TYPE\n",
      "WASI\n",
      "WAIS\n",
      "WISC\n",
      "WISC_IV_FULL\n",
      "WAIS_III\n",
      "WISC_III_DUTCH\n",
      "WST\n",
      "-9999\n",
      "HAWIK_IV\n",
      "WISC_IV_4_SUBTESTS\n",
      "WISC_III\n",
      "nan\n",
      "GIT\n",
      "DAS_II_SA\n",
      "\n",
      "Feature: VIQ_TEST_TYPE\n",
      "WASI\n",
      "WAIS\n",
      "WISC\n",
      "nan\n",
      "WAIS_III\n",
      "GIT\n",
      "WISC_IV_FULL\n",
      "DAS_II_SA\n",
      "WASI    \n",
      "PPVT\n",
      "WISC4   \n",
      "PPVT    \n",
      "ppvt\n",
      "Stanford\n",
      "WISC_III\n",
      "\n",
      "Feature: PIQ_TEST_TYPE\n",
      "WASI\n",
      "WAIS\n",
      "WISC\n",
      "nan\n",
      "WAIS_III\n",
      "RAVENS\n",
      "GIT\n",
      "WISC_IV_FULL\n",
      "DAS_II_SA\n",
      "WASI    \n",
      "Ravens\n",
      "WISC4   \n",
      "Ravens  \n",
      "ravens\n",
      "Stanford\n",
      "WISC_III\n",
      "\n",
      "Feature: COMORBIDITY\n",
      "nan\n",
      "ODD\n",
      "ADHD (inattentive; present); ODD; MDE (past); Phobia (simple and social)\n",
      "ADHD Combined Type; ODD; and Specific Phobia (bugs/thunderstorms)\n",
      "ADHD Combined and ODD\n",
      "MDE (past); Dysthymic disorder\n",
      "ADHD Combined; GAD;phobia\n",
      "ADHD Combined\n",
      "ADHD Combined; ODD; Phobias (cats; bugs; riding in trains and trolleys; being in crowds; and seeing blood)\n",
      "simple phobia- bridges\n",
      "ADHD Inattentive \n",
      "Phobia\n",
      "Specific phobia:  spiders; dark; thunderstorms\n",
      "ADHD Combined; GAD\n",
      "ADHD Inattentive\n",
      "Anxiety Disorder NOS;\n",
      "Anxiety Disorder NOS; Mood Disorder NOS\n",
      "ADHD Hyperactive/Impulsive\n",
      "Mood Disorder NOS\n",
      "ADHD NOS\n",
      "ADHD Combined and Specific Phobia\n",
      "ADHD Combined; Encopresis\n",
      "Generalized Anxiety Disorder; Specific Phobia: bugs; dogs; elevators\n",
      "ADHD\n",
      "Diurnal & Nocturnal Enuresis; Encopresis; Transient Tic Disorder\n",
      "Generalized Anxiety Disorder\n",
      "Specific Phobia: going down the stairs\n",
      "Anxiety Disorder NOS\n",
      "Mood Disorder NOS; Separation Anxiety Dx; Enuresis\n",
      "Social Phobia; Specific Phobia: spiders \n",
      "Anxiety Disorder NOS & Depressive Disorder NOS in full remisison (on Tretament)\n",
      "Enuresis; Tic Disorder NOS\n",
      "Generalized Anxiety Disorder; Specific phobia; Enuresis; Encopresis\n",
      "Specific Phobia: Butterflies\n",
      "Disruptive disorder NOS\n",
      "Dysthymia\n",
      "Dysthymia \n",
      "Dysthymia  \n",
      "Specific Phobia: needles/shots \n",
      "Dysthymia; Agoraphobia dx; \n",
      "Social Phobia; \n",
      "Mood NOS\n",
      "None \n",
      "-9999\n",
      "\n",
      "Feature: CURRENT_MED_STATUS\n",
      "nan\n",
      "1\n",
      "0\n",
      "-9999\n",
      "`\n",
      "\n",
      "Feature: MEDICATION_NAME\n",
      "nan\n",
      "Atomoxetine; Sertraline\n",
      "Dextroamphetamine and amphetamine; Fluoxetine\n",
      "Valproic acid; Lithium; Risperidone\n",
      "Zolpidem; Lisinopril; Topiramato; Trazodone; Venlafaxine;  Bupropion; \n",
      "Citalopram; Methylphenidated Extended release; Methylphenidate\n",
      "Methylphenidate; Merthylphenidate Extended Release\n",
      "Fluoxetine; Buproprion\n",
      "Merthylphenidate Extended Release\n",
      "Lisdexamfetamine\n",
      "Guanfacine\n",
      "Fluoxetine; Methylphenidate\n",
      "Citalopram; Risperidone\n",
      "Guanfacine Extended Release\n",
      "Dexmethylphenidate; Guanfacine; Clonidine; Melatonin\n",
      "Dexmethylphenidate\n",
      "Valproic Acid\n",
      "Escitalopram; Dexmethylphenidate\n",
      "Methylphenidate Transdermal;Guanfacine Extended Release; Citalopram\n",
      "0\n",
      "Fluoxetine Hcl; Bupropion\n",
      "Methylphenidate; Risperidone\n",
      "Lamotrigine; Lithium Carbonate\n",
      "Benperidol\n",
      "Atomoxetine hydrochloride; Methylphenidate \n",
      "Methylphanidate\n",
      "Eszopiclone; Citalopram; Lorazepam\n",
      "Escitalopram; Clonidine\n",
      "Methylphenidate Extended Release\n",
      "Methylphenidate Extended Release; Sertraline\n",
      "Amphetamine and Dextroamphetamine Extended Release; Atomoxetine; Amphetamine and dextroamphetamine\n",
      "Fluoxetine\n",
      "Methylphenidate Extended Release; Sertraline; Mirtazapine \n",
      "Escitalopram\n",
      "Guanfacine Extended Release; Sertraline\n",
      "Methylphenidate Extended Release; Metadate\n",
      "Concerta\n",
      "Bupropion; Duloxetine; Methylphenidate Extended Release\n",
      "Mirtazapine\n",
      "Amphetamine and Dextroamphetamine\n",
      "Amphetamine andDdextroamphetamine\n",
      "Citalopram; Methylphenidate; Bupropion; Trazadone\n",
      "Oxcarbazepine; Sertraline; Methylphenidate Extended Release; Bupropion\n",
      "Aripiprazole; Venlafaxine\n",
      "Citalopram; Dextroamphetamine and Amphetamine; Dexedrine\n",
      "Risperidone; Strattera; Methylphenidate\n",
      "Dextroamphetamine and Amphetamine \n",
      "Risperidone\n",
      "Risperidone; Sertraline\n",
      "Methylphenidate Extended Release; Methylphenidate\n",
      "Methylphenidate; Methylphenidate Extended Release; Risperidone; Dextroamphetamine and Amphetamine \n",
      "Sertraline\n",
      "Pantoprazole\n",
      "Atomoxetine\n",
      "Methylphenidate; Citalopram \n",
      "Sertraline; Risperidone; Dextroamphetamine and Amphetamine\n",
      "Antidepressant\n",
      "Atomoxetine; Risperidone; Methylphenydate\n",
      "Methylphenidate; Guanfacine; Valproic Acid; Bupropion; dextroamphetamine and amphetamine\n",
      "Sertraline; Risperidone\n",
      "Citalopram \n",
      "Dextroamphetamine and amphetamine; Citaopram; Risperidone; Paliperidone\n",
      "Methylphenidate Extended Release; Methylphenidate \n",
      "Methylphenidate; Methylphenidate Extended Release\n",
      "Citalopram; Bupropion\n",
      "Atomoxetine; Lisdexamfetamine; Bupropion Extended Release; Guanfacine Extended Release\n",
      "Tenex; \n",
      "Escitalopram; methlphenidate Extended Release\n",
      "Aripiprazole\n",
      "Dextramphetamine and Amphetamine\n",
      "Sertraline; Guanfacine; Aripiprazole\n",
      "Citolopram\n",
      "Risperidone; Atomoxetine; Guanfacine\n",
      "Aripiprazole; Escitalopram; Bupropion; Zinc \n",
      "Risperdone\n",
      "Ziprasidone\n",
      "Lamotrigine; Asenapine ; Lisdexamfetamine\n",
      "Allegra\n",
      "Aripiprazole; Melatonin; Sertraline;CoQ10 ; \n",
      "Escitalopram; Valproic Acid; Guanfacine\n",
      "Atomoxetine; Methylphenidate transdermal patch\n",
      "Methylphenidate transdermal patch\n",
      "Dexmethylphenidate; Citalopram; Atomoxetine; Methylphenidate transdermal patch\n",
      "Dextroamphetamine and Amphetamine; Risperidone; Fluoxetine\n",
      "Levothyroxine\n",
      "Dextroamphetamine and Amphetamine; Buspirone\n",
      "Fluoxetine; Oxcarbazepine\n",
      "Risperidone; Peroxatine; Methylphenidate Extended Release\n",
      "Clonidine; Risperidone; Atomoxetine\n",
      "Dextroamphetamine and Amphetamine\n",
      "Fluoxetine; Buspirone; Atomoxetine\n",
      "Dextroamphetamine and Amphetamine;Valproic acid; Quetiapine; Sertraline; Melatonin\n",
      "Fluoxetine; Atomoxetine\n",
      "Methylphenidate extended release\n",
      "Dextroamphetamine and amphetamine; Fluoxetine; Risperidone\n",
      "Risperidone; Quetiapine\n",
      "Sertraline; Guanfacine; altrex\n",
      "Paroxetine; Lisdexamfetamine\n",
      "Aripiprazole; Synthroid\n",
      "Sertraline; Ziprasidone; Lisdexamfetamine\n",
      "Methylphenidate extended release; Risperidone; Methylphenidate; Guanfacine\n",
      "Dextroamphetamine and Amphetamine; Melatonin; Trazodone\n",
      "Aripiprazole; Sertraline; melatonin\n",
      "Methylphenidate extended release; Risperidone\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seleziona tutte le colonne di tipo 'object'\n",
    "object_columns = ASD_phenotypic.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Converti le colonne selezionate in tipo 'categorical'\n",
    "ASD_phenotypic[object_columns] = ASD_phenotypic[object_columns].astype('category')\n",
    "\n",
    "\n",
    "# Seleziona solo le colonne di tipo 'category'\n",
    "category_columns = ASD_phenotypic.select_dtypes(include=['category'])\n",
    "\n",
    "# Ciclo su tutte le colonne di tipo 'category'\n",
    "for column in category_columns.columns:\n",
    "    # Stampa il nome della colonna\n",
    "    print(\"Feature:\", column)\n",
    "    # Stampa i valori unici della colonna\n",
    "    for value in category_columns[column].unique():\n",
    "        print(value)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploding categorical features, we notice the presence of value -9999, commonly used to denote missing data or values out of range, so we are going to consider them as NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sostituisci il valore -9999 con NaN in tutto il DataFrame\n",
    "ASD_phenotypic.replace([-9999, \"-9999\"], np.nan, inplace=True)\n",
    "#ASD_phenotypic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ottieni i nomi delle colonne categoriche come una lista\n",
    "categorical_column_names = category_columns.columns.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1112 entries, 0 to 1111\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   SITE_ID              1112 non-null   category\n",
      " 1   HANDEDNESS_CATEGORY  797 non-null    category\n",
      " 2   FIQ_TEST_TYPE        947 non-null    category\n",
      " 3   VIQ_TEST_TYPE        834 non-null    category\n",
      " 4   PIQ_TEST_TYPE        853 non-null    category\n",
      " 5   COMORBIDITY          64 non-null     category\n",
      " 6   CURRENT_MED_STATUS   817 non-null    category\n",
      " 7   MEDICATION_NAME      157 non-null    category\n",
      "dtypes: category(8)\n",
      "memory usage: 18.1 KB\n"
     ]
    }
   ],
   "source": [
    "category_columns.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand better how to treat the information gived by this categorical variables we are interested in know which values are stored in this features. We will analyze all of them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the implemented tolist, we can acced to specific elements.\n",
    "We prefer create viasual subsections in order to manage these features, but we could implement a 'for logic' in order to guarantee a correct automatic work also in case of modifications on dataset.\n",
    "\n",
    "For each categorical feature, we want to investigate the amount of informations given. We suppose that for our specific scope we could drop some uninformative features, but we want to proof it. In which way? \n",
    "- Evaluating the amount of info considering Nan as Nan\n",
    "- Changing Missing values with specific feature engineering rules\n",
    "- Evaluating the amount of info with Nan evalueted\n",
    "\n",
    "We use Entropy logic.\n",
    "If both have high level of entropy we can drop the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converti tutte le stringhe delle colonne categoriche in minuscolo\n",
    "category_columns_upper = ASD_phenotypic.select_dtypes(include='category').apply(lambda x: x.str.upper())\n",
    "\n",
    "# Sostituisci le colonne originali con quelle convertite in minuscolo\n",
    "ASD_phenotypic[category_columns_upper.columns] = category_columns_upper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SITE_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SITE_ID refers to the place where the data from the subject was recluted. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SITE_ID\n",
       "NYU         184\n",
       "UM_1        110\n",
       "USM         101\n",
       "UCLA_1       82\n",
       "MAX_MUN      57\n",
       "PITT         57\n",
       "YALE         56\n",
       "KKI          55\n",
       "TRINITY      49\n",
       "STANFORD     40\n",
       "CALTECH      38\n",
       "SDSU         36\n",
       "OLIN         36\n",
       "LEUVEN_2     35\n",
       "UM_2         35\n",
       "SBL          30\n",
       "LEUVEN_1     29\n",
       "OHSU         28\n",
       "CMU          27\n",
       "UCLA_2       27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accesso a una specifica colonna categorica utilizzando la lista di nomi\n",
    "specific_category_column = ASD_phenotypic[categorical_column_names[0]].value_counts(dropna=False)\n",
    "specific_category_column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is data that has been collected from the same center that we decide to unify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SITE_ID\n",
       "NYU         184\n",
       "UM          145\n",
       "UCLA        109\n",
       "USM         101\n",
       "LEUVEN       64\n",
       "PITT         57\n",
       "MAX_MUN      57\n",
       "YALE         56\n",
       "KKI          55\n",
       "TRINITY      49\n",
       "STANFORD     40\n",
       "CALTECH      38\n",
       "SDSU         36\n",
       "OLIN         36\n",
       "SBL          30\n",
       "OHSU         28\n",
       "CMU          27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a function to replace the categories for the indicated cases\n",
    "\n",
    "def replace_categories(category):\n",
    "    if \"UCLA\" in category:\n",
    "        return \"UCLA\"\n",
    "    if \"LEUVEN\" in category:\n",
    "        return \"LEUVEN\"\n",
    "    if \"UM\" in category:\n",
    "        return \"UM\"\n",
    "    else:\n",
    "        return category\n",
    "\n",
    "# Then we apply the replace function\n",
    "ASD_phenotypic[categorical_column_names[0]] = ASD_phenotypic[categorical_column_names[0]].apply(replace_categories)\n",
    "\n",
    "# Now we check the new order\n",
    "specific_category_column = ASD_phenotypic[categorical_column_names[0]].value_counts(dropna=False)\n",
    "specific_category_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HANDEDNESS_CATEGORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HANDEDNESS_CATEGORY refers to the handedness of the subject. We don't really know if there is a correlation or not between the Autism Disease and the handnedness of the subject and as it is a caracteristic of the subject itselfs and not of the specific site of analysis as in the previous case, we decide to work with this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HANDEDNESS_CATEGORY\n",
       "R        693\n",
       "NaN      326\n",
       "L         71\n",
       "AMBI      15\n",
       "MIXED      6\n",
       "L->R       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accesso a una specifica colonna categorica utilizzando la lista di nomi\n",
    "specific_category_column = ASD_phenotypic[categorical_column_names[1]].value_counts(dropna=False)\n",
    "specific_category_column\n",
    "#hiii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are incongruences for the Ambidextreus group, so we will replace them (Mixed and L->R) for Ambi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HANDEDNESS_CATEGORY\n",
       "R       693\n",
       "NaN     326\n",
       "L        71\n",
       "AMBI     22\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We decide to replace all the values with \"Mixed\" or \"L->R\" with \"Ambi\"\n",
    "def replace_categories(category):\n",
    "    if category in ['MIXED', 'L->R']:\n",
    "        return 'AMBI'\n",
    "    else:\n",
    "        return category\n",
    "\n",
    "# Apply the custom function to the categorical column\n",
    "ASD_phenotypic[categorical_column_names[1]] = ASD_phenotypic[categorical_column_names[1]].apply(replace_categories)\n",
    "\n",
    "# Display the new result\n",
    "specific_category_column = ASD_phenotypic[categorical_column_names[1]].value_counts(dropna=False)\n",
    "specific_category_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be applied at the final????\n",
    "\n",
    "We can see that we have values for R, L and Ambi, Mixed, L->R. The dataset include as a feature also a handness score where right-handed subjects has positive score (max = 100), left-handed subjects negative score (min = -100) and ambidextreus subjects has 0 score. \n",
    "\n",
    "To be coherent with that categorization and can properly evaluate if one of those features contain redudant information or that can be merged in some manner, we decide to assign to R values the number \"100\", to L values the number \"-100\" and to Ambi, Mixed, L->R the number \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIQ_TEST_TYPE, VIQ_TEST_TYPE and PIQ_TEST_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIQ_TEST_TYPE, VIQ_TEST_TYPE and PIQ_TEST_TYPE refers to the type of test that each center chose to get the information of FIQ_TEST, VIQ_TEST and PIQ_TEST respectively. As we want our clustering algorithm to be as most general as possible, we want to be able to categorize subjects in despise of the test used by the centers to get the data. So we decide to drop this feature as well.\n",
    "\n",
    "Note that if in a future we will be interested in to analyze if there are differences between the clustering score obtained using the result for each difference test we'll can retrieve the information opportunely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIQ_TEST_TYPE\n",
      "WASI                  551\n",
      "NaN                   169\n",
      "WISC_IV_FULL          103\n",
      "WAIS_III               63\n",
      "DAS_II_SA              56\n",
      "WST                    41\n",
      "WISC_III_DUTCH         35\n",
      "WISC_IV_4_SUBTESTS     33\n",
      "WISC                   28\n",
      "WISC_III               15\n",
      "HAWIK_IV               14\n",
      "WAIS                    3\n",
      "GIT                     1\n",
      "Name: count, dtype: int64\n",
      "______________________________________\n",
      "\n",
      "VIQ_TEST_TYPE\n",
      "WASI            508\n",
      "NaN             278\n",
      "PPVT             96\n",
      "DAS_II_SA        69\n",
      "WISC_IV_FULL     47\n",
      "WAIS_III         43\n",
      "WISC             28\n",
      "PPVT             24\n",
      "GIT               8\n",
      "WASI              5\n",
      "WAIS              3\n",
      "WISC4             1\n",
      "STANFORD          1\n",
      "WISC_III          1\n",
      "Name: count, dtype: int64\n",
      "______________________________________\n",
      "\n",
      "PIQ_TEST_TYPE\n",
      "WASI            508\n",
      "NaN             259\n",
      "RAVENS          127\n",
      "DAS_II_SA        70\n",
      "WISC_IV_FULL     47\n",
      "WAIS_III         43\n",
      "WISC             28\n",
      "RAVENS           11\n",
      "GIT               8\n",
      "WASI              5\n",
      "WAIS              3\n",
      "WISC4             1\n",
      "STANFORD          1\n",
      "WISC_III          1\n",
      "Name: count, dtype: int64\n",
      "______________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (2,5):\n",
    "    specific_category_column = ASD_phenotypic[categorical_column_names[i]].value_counts(dropna=False)\n",
    "    print(specific_category_column)\n",
    "    print('______________________________________\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make some little changes in the categories in order to homogenize the data. NOT WORKINGGGGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIQ_TEST_TYPE\n",
      "WASI     551\n",
      "WISC     214\n",
      "NaN      169\n",
      "WAIS      66\n",
      "DAS       56\n",
      "WST       41\n",
      "HAWIK     14\n",
      "GIT        1\n",
      "Name: count, dtype: int64\n",
      "______________________________________\n",
      "\n",
      "VIQ_TEST_TYPE\n",
      "WASI        513\n",
      "NaN         278\n",
      "PPVT        120\n",
      "WISC         77\n",
      "DAS          69\n",
      "WAIS         46\n",
      "GIT           8\n",
      "STANFORD      1\n",
      "Name: count, dtype: int64\n",
      "______________________________________\n",
      "\n",
      "PIQ_TEST_TYPE\n",
      "WASI        513\n",
      "NaN         259\n",
      "RAVENS      138\n",
      "WISC         77\n",
      "DAS          70\n",
      "WAIS         46\n",
      "GIT           8\n",
      "STANFORD      1\n",
      "Name: count, dtype: int64\n",
      "______________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We create a function to replace the categories for the indicated cases\n",
    "\n",
    "def replace_categories(category):\n",
    "    if pd.isna(category):  # Controlla se il valore è NaN\n",
    "        return category  # Se è NaN, restituisci lo stesso valore\n",
    "    if \"WASI\" in category:\n",
    "        return \"WASI\"\n",
    "    if \"WISC\" in category:\n",
    "        return \"WISC\"\n",
    "    if \"WAIS\" in category:\n",
    "        return \"WAIS\"\n",
    "    if \"DAS\" in category:\n",
    "        return \"DAS\"\n",
    "    if \"HAWIK\" in category:\n",
    "        return \"HAWIK\"\n",
    "    if \"PPVT\" in category:\n",
    "        return \"PPVT\"\n",
    "    if \"RAVENS\" in category:\n",
    "        return \"RAVENS\"\n",
    "    else:\n",
    "        return category\n",
    "\n",
    "for i in range (2,5):\n",
    "    ASD_phenotypic[categorical_column_names[i]] = ASD_phenotypic[categorical_column_names[i]].apply(replace_categories)\n",
    "    specific_category_column = ASD_phenotypic[categorical_column_names[i]].value_counts(dropna=False)\n",
    "    print(specific_category_column)\n",
    "    print('______________________________________\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMORBIDITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMORBIDITY indicates if the subject present some othe pathology or disease or particular detail that is important to specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'COMORBIDITY'\n",
    "\n",
    "# Get unique values and their frequencies\n",
    "unique_values_counts = ASD_phenotypic[column_name].value_counts(dropna=False)\n",
    "\n",
    "# Display unique values and their frequencies\n",
    "print(\"Unique values in column '{}' and their frequencies:\".format(column_name))\n",
    "for value, count in unique_values_counts.items():\n",
    "    print(\"{}: {}\".format(value, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a lot of variability between the commorbities and the combinations of them in the patients. We note as well that there is a large quantity of NaN values. To understand better how the data was collected and how to work with it, we want to understand if the large amount of NaN is due to differences in the protocols between different centers of data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nan_counts = ASD_phenotypic.groupby('SITE_ID')['COMORBIDITY'].count()\n",
    "print(non_nan_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we anticipated, it seems that only NYU, KKI and SBL collected data about the commorbities. We can also note that they didn't collected it for all their subjects (total subjects for NIU = 184, KKI = 55, SBL = 30). In this way is difficult to understand how to treat the other subjects, because there isn' a clear tendency to follow. We can ipotetize that the other centers didn't collect data about commorbities, but we can't say with security that the missing values for the NYU, KKI and SBL center mean that the other subjects haven't commorbities. \n",
    "\n",
    "Taking into account the existent limitance in the available data, we decided that the less risky option is to treat the NaN values as None, while for the other commorbities we will reduce them to macrogroups. As our other dataset is about ADH, the selected macrogroups are: \n",
    "- patients that presents a form of ADHD, catalogated as ADHD\n",
    "- patients that has other disorders, catalogated as OTHER_MENTAL_DISORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To make this we create a function that is able to treat each case as we defined\n",
    "import re\n",
    "\n",
    "def replace_value(x):\n",
    "    if pd.isna(x) or x == \"None\":\n",
    "        return \"None\"\n",
    "    elif re.search(r'\\bADHD\\b', x, flags=re.IGNORECASE):\n",
    "        return \"ADHD\"\n",
    "    else:\n",
    "        return \"OTHER_MENTAL_DISORDER\"\n",
    "\n",
    "# Assuming your DataFrame is named 'data' and the column with strings is named 'feature'\n",
    "# Apply the function to the 'feature' column\n",
    "ASD_phenotypic['COMORBIDITY'] = ASD_phenotypic['COMORBIDITY'].apply(replace_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we check the new distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'COMORBIDITY'\n",
    "\n",
    "# Get unique values and their frequencies\n",
    "unique_values_counts = ASD_phenotypic[column_name].value_counts(dropna=False)\n",
    "\n",
    "# Display unique values and their frequencies\n",
    "print(\"Unique values in column '{}' and their frequencies:\".format(column_name))\n",
    "for value, count in unique_values_counts.items():\n",
    "    print(\"{}: {}\".format(value, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CURRENT_MED_STATUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature indicates if the subject is taking any medication or not. If the subject doesn't take any medication is labeled with a \"0\" in the other case with a \"1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'CURRENT_MED_STATUS'\n",
    "\n",
    "# Get unique values and their frequencies\n",
    "unique_values_counts = ASD_phenotypic[column_name].value_counts(dropna=False)\n",
    "\n",
    "# Display unique values and their frequencies\n",
    "print(\"Unique values in column '{}' and their frequencies:\".format(column_name))\n",
    "for value, count in unique_values_counts.items():\n",
    "    print(\"{}: {}\".format(value, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the only attribute that is not numeric is the \"`\", we will catalogate it as a NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic['CURRENT_MED_STATUS'] = ASD_phenotypic['CURRENT_MED_STATUS'].replace('`', float('nan'), regex=True)\n",
    "\n",
    "unique_values_counts = ASD_phenotypic[column_name].value_counts(dropna=False)\n",
    "\n",
    "print(\"Unique values in column '{}' and their frequencies:\".format(column_name))\n",
    "for value, count in unique_values_counts.items():\n",
    "    print(\"{}: {}\".format(value, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEDICATION_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature indicate which are the principals active ingredients of the medication that the patient is taking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'MEDICATION_NAME'\n",
    "\n",
    "# Get unique values and their frequencies\n",
    "unique_values_counts = ASD_phenotypic[column_name].value_counts(dropna=False)\n",
    "\n",
    "# Display unique values and their frequencies\n",
    "print(\"Unique values in column '{}' and their frequencies:\".format(column_name))\n",
    "for value, count in unique_values_counts.items():\n",
    "    print(\"{}: {}\".format(value, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to make a categorization of the pharmacs based on the mechanism of action in the following way:\n",
    "\n",
    "- Antidepressant: Citalopram (Citaopram)(Citolopram), Fluoxetine, Sertraline, Escitalopram, Trazodone, Peroxatine (Paroxetine), Antidepressant,Venlafaxine, Mirtazapine, Venlafaxine, Duloxetine, Buspirone\n",
    "\n",
    "- Neurostimulant (ADHD): Methylphenidate (methlphenidate)(Methylphanidate)(Merthylphenidate)(Methylphenidated)(Metadate), Lisdexamfetamine, Dexmethylphenidate, Dextroamphetamine(Dextramphetamine)(Dexedrine)(andDdextroamphetamine) and amphetamine, Bupropion (Buproprion), Concerta, Atomoxetine, Strattera\n",
    "\n",
    "- Antipsychotic: Risperidone (Risperdone), Paliperidone, Ziprasidone, Aripiprazole, Asenapine, Quetiapine, Benperidol, Guanfacine, tenex, Clonidine\n",
    "\n",
    "- Mood stabiliser: Lamotrigine, Oxcarbazepine, Topiramato, Valproic Acid, Altrex, Eszopiclone, Lorazepam, Lithium Carbonate (Lithium), Zolpidem\n",
    "\n",
    "- Hypothyroidism treatment: Levothyroxine, Synthroid\n",
    "\n",
    "- Antihypertensives: Lisinopril, Clonidine\n",
    "\n",
    "- Gastrointestinal medication: Pantoprazole\n",
    "\n",
    "- Antihistamine: Allegra\n",
    "\n",
    "- Dietary supplements: Zinc, CoQ10, Melatonin, hydrochloride (HCl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionaries for each category of medication\n",
    "categories = {\n",
    "    \"Antidepressant\": [\"Citalopram\", \"Citaopram\", \"Citolopram\", \"Fluoxetine\", \"Sertraline\", \"Escitalopram\", \"Trazodone\", \"Peroxatine\", \"Paroxetine\", \"Venlafaxine\", \"Mirtazapine\", \"Duloxetine\", \"Buspirone\"],\n",
    "    \"Neurostimulant (ADHD)\": [\"Methylphenidate\", \"methlphenidate\", \"Methylphanidate\", \"Merthylphenidate\", \"Methylphenidated\", \"Metadate\", \"Lisdexamfetamine\", \"Dexmethylphenidate\", \"Dextroamphetamine\", \"Dextramphetamine\", \"Dexedrine\", \"andDdextroamphetamine\", \"amphetamine\", \"Bupropion\", \"Buproprion\", \"Concerta\", \"Atomoxetine\", \"Strattera\"],\n",
    "    \"Antipsychotic\": [\"Risperidone\", \"Risperdone\", \"Paliperidone\", \"Ziprasidone\", \"Aripiprazole\", \"Asenapine\", \"Quetiapine\", \"Benperidol\", \"Guanfacine\", \"tenex\", \"Clonidine\"],\n",
    "    \"Mood stabiliser\": [\"Lamotrigine\", \"Oxcarbazepine\", \"Topiramato\", \"Valproic Acid\", \"Altrex\", \"Eszopiclone\", \"Lorazepam\", \"Lithium Carbonate\", \"Lithium\", \"Zolpidem\"],\n",
    "    \"Hypothyroidism treatment\": [\"Levothyroxine\", \"Synthroid\"],\n",
    "    \"Antihypertensives\": [\"Lisinopril\", \"Clonidine\"],\n",
    "    \"Gastrointestinal medication\": [\"Pantoprazole\"],\n",
    "    \"Antihistamine\": [\"Allegra\"],\n",
    "    \"Dietary supplements\": [\"Zinc\", \"CoQ10\", \"Melatonin\", \"hydrochloride\", \"HCl\"]\n",
    "}\n",
    "\n",
    "# Create an empty dictionary to store medication counts for each subject\n",
    "medication_counts = {}\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in ASD_phenotypic.iterrows():\n",
    "    subject_id = row['SUB_ID']\n",
    "    medication_name = row['MEDICATION_NAME']\n",
    "\n",
    "    # Skip NaN values\n",
    "    if pd.isnull(medication_name):\n",
    "        continue\n",
    "    \n",
    "    # Count the occurrences of each medication category for the current subject\n",
    "    category_count = {category: 0 for category in categories}\n",
    "    for category, meds in categories.items():\n",
    "        for med in meds:\n",
    "            if med.lower() in medication_name.lower():\n",
    "                category_count[category] += 1\n",
    "    \n",
    "    # Store the medication counts for the current subject\n",
    "    medication_counts[subject_id] = category_count\n",
    "\n",
    "# Convert the dictionary to a DataFrame for visualization\n",
    "medication_counts_df = pd.DataFrame.from_dict(medication_counts)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(medication_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "medication_counts_df.sum(axis=1).sort_values(ascending=False).plot(kind='bar', color='skyblue')\n",
    "plt.title('Total Medication Counts for Each Subject')\n",
    "plt.xlabel('Subject ID')\n",
    "plt.ylabel('Total Medication Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the dataset: Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUMERICAL EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 1112 raws anf 74 colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check the presence of missing values catalogated as None or numpy.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_values = ASD_phenotypic.isna().sum()\n",
    "\n",
    "# Filter columns with NaN values\n",
    "columns_with_nan = nan_values[nan_values > 0]\n",
    "\n",
    "\n",
    "# Print the number of attributes with NaN values\n",
    "print(\"Number of attributes with NaN values:\", len(columns_with_nan))\n",
    "\n",
    "# Print the columns with NaN values and their corresponding counts\n",
    "print(\"Attributes with NaN values and their counts:\")\n",
    "pd.set_option('display.max_rows', 74)\n",
    "columns_with_nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of NANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_values.plot(kind='barh', figsize=(12,12), title='Missing values per feature')\n",
    "plt.xlabel('Number of missing values')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there some attribute with only missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_only_nan = nan_values[nan_values == ASD_phenotypic.shape[0]]\n",
    "print(len(columns_only_nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are too much, maybe is usefull to understand which columns haven't NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns without NaN values\n",
    "columns_without_nan = nan_values[nan_values == 0]\n",
    "\n",
    "# Print the columns with NaN values and their corresponding counts\n",
    "print(\"Attributes without NaN values and their counts:\")\n",
    "columns_without_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are maybe some subjects that has only missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_values = ASD_phenotypic.T.isna().sum()\n",
    "\n",
    "# Filter columns with NaN values\n",
    "subjects_with_nan = nan_values[nan_values > 0]\n",
    "\n",
    "print(\"Max missing values encountered for a subject: \" +str(max(subjects_with_nan)))\n",
    "print(\"Min missing values encountered for a subject: \" +str(min(nan_values)))\n",
    "subjects_with_nan.plot(kind='hist', bins=22, figsize=(10,6), title='Missing values per subject')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on the general statistics for the numerical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to handle missing values. But how?\n",
    "Is really necessary to fullfill all of them? Can we maybe make some feature selection previously?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make random forest for features selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Assuming 'data' is your DataFrame and 'target' is your target variable\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['target']), data['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert categorical variables to numeric using one-hot encoding (if needed)\n",
    "# For example:\n",
    "# X_train = pd.get_dummies(X_train)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance scores\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Optionally, visualize feature importances\n",
    "# (e.g., create a bar plot with feature names on the x-axis and importance scores on the y-axis)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vogliamo individuare e capire cosa sono questi object\n",
    "numeric = ASD_phenotypic.select_dtypes(include=['float64',\"int64\"]).dropna()\n",
    "numeric.T\n",
    "f,ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(numeric.drop('DX_GROUP',axis = 1).corr(), \n",
    "            annot=True, \n",
    "            linewidths=.5, \n",
    "            fmt= '.2f',\n",
    "            ax=ax,\n",
    "            vmin=-1, \n",
    "            vmax=1,\n",
    "            cmap = \"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop attribute if:\n",
    "- Only unique values\n",
    "- Only missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Calcola la distribuzione delle frequenze dei valori non mancanti nella feature 'SITE_ID'\n",
    "site_id_counts = ASD_phenotypic[categorical_column_names[0]].value_counts(dropna=True)\n",
    "\n",
    "# Calcola la proporzione di ciascun valore rispetto al totale dei dati\n",
    "site_id_proportions = site_id_counts / site_id_counts.sum()\n",
    "\n",
    "# Calcola l'entropia della distribuzione dei valori non mancanti\n",
    "site_id_entropy = -(site_id_proportions * np.log2(site_id_proportions)).sum()\n",
    "\n",
    "# Stampa l'entropia della feature 'SITE_ID'\n",
    "print('Considering the feature')\n",
    "print(\"Entropia di SITE_ID:\", site_id_entropy)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(column):\n",
    "    # Sostituisci i valori NaN con \"Missing\" solo se la colonna è di tipo object\n",
    "    if column.dtype == 'category':\n",
    "        # Aggiungi \"Missing\" alle categorie esistenti\n",
    "        column = column.cat.add_categories(\"Missing\")\n",
    "        column_filled = column.fillna(\"Missing\")\n",
    "    else:\n",
    "        column_filled = column.fillna(\"Missing\")  # Se è numerica\n",
    "        \n",
    "    # Calcola la distribuzione di probabilità delle categorie\n",
    "    value_counts = column_filled.value_counts()\n",
    "    probabilities = value_counts / value_counts.sum()\n",
    "    \n",
    "    # Calcola l'entropia\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    \n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy with \"Missing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola l'entropia per tutte le colonne\n",
    "all_entropy = {}\n",
    "for column in ASD_phenotypic.columns:\n",
    "    all_entropy[column] = calculate_entropy(ASD_phenotypic[column])\n",
    "\n",
    "# Ordina il dizionario in base ai valori di entropia in ordine decrescente\n",
    "sorted_entropy = {k: v for k, v in sorted(all_entropy.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# Plot dell'entropia per tutte le colonne\n",
    "# Definisci i colori per le feature categoriche e numeriche\n",
    "color_categorical = 'skyblue'\n",
    "color_numerical = 'lightgreen'\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(sorted_entropy.keys(), sorted_entropy.values(), color=[color_categorical if col in category_columns.columns else color_numerical for col in sorted_entropy.keys()])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Entropy')\n",
    "plt.title('Entropy of All Features (NaN treated as \"Missing\" for object types)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy with NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo dell'entropia per tutte le colonne\n",
    "all_entropy_dropna = {}\n",
    "\n",
    "for column in ASD_phenotypic.columns:\n",
    "    # Rimuovi i valori NaN dalla colonna\n",
    "    column_without_nan = ASD_phenotypic[column].dropna()\n",
    "    \n",
    "    # Se la colonna è vuota dopo aver rimosso i NaN, imposta l'entropia a 0\n",
    "    if column_without_nan.empty:\n",
    "        entropy = 0\n",
    "    else:\n",
    "        # Calcola la distribuzione di probabilità delle categorie\n",
    "        value_counts = column_without_nan.value_counts()\n",
    "        probabilities = value_counts / value_counts.sum()\n",
    "        \n",
    "        # Calcola l'entropia\n",
    "        entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    # Memorizza l'entropia calcolata per la colonna\n",
    "    all_entropy_dropna[column] = entropy\n",
    "\n",
    "# Plot dell'entropia per tutte le colonne\n",
    "# Ordina il dizionario in base ai valori di entropia in ordine decrescente\n",
    "sorted_entropy_dropna = {k: v for k, v in sorted(all_entropy_dropna.items(), key=lambda item: item[1], reverse=True)}\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(sorted_entropy_dropna.keys(), sorted_entropy_dropna.values(), color=[color_categorical if col in category_columns.columns else color_numerical for col in sorted_entropy_dropna.keys()])\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Entropy')\n",
    "plt.title('Entropy of All Features (NaNs Ignored)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between two entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sovrapposizione dei due plot\n",
    "\n",
    "# Calcola le differenze tra le entropie con e senza NaN per ogni feature\n",
    "differences = {}\n",
    "for column in all_entropy.keys():\n",
    "    difference = all_entropy_dropna[column] - all_entropy[column]\n",
    "    differences[column] = difference\n",
    "\n",
    "# Crea il grafico a dispersione delle differenze\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(range(len(differences)), list(differences.values()), color='skyblue')\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=1)  # Aggiungi una linea orizzontale a y=0 per la visualizzazione\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Difference in Entropy (Drop NaN - Keep NaN)')\n",
    "plt.title('Scatter Plot of Entropy Differences (Drop NaN vs Keep NaN)')\n",
    "plt.xticks(range(len(differences)), list(differences.keys()), rotation=90)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
