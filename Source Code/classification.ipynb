{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt #for the plots\n",
    "import OurFunctions as of\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_original = pd.read_csv(os.path.join('DataSets','Phenotypic Datasets','ASD_phenotypic.csv'))\n",
    "ASD_phenotypic = pd.read_csv(os.path.join('DataSets','Phenotypic Datasets','ASD_phenotypic_preprocessed.csv'))\n",
    "ASD_diagnosis = pd.read_csv(os.path.join('DataSets','Phenotypic Datasets','ASD_clinical.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(features_df, target_df, classifier, scaler=None, encoder=None, k=5):\n",
    "    # Separazione delle feature e del target\n",
    "    X = features_df  # Utilizziamo il DataFrame delle features senza modifiche\n",
    "    #y = target_df['DX_GROUP']  # Utilizziamo la colonna target come y direttamente\n",
    "    y = target_df\n",
    "    # Encoding delle features da numeriche a categoriche (opzionale)\n",
    "    if encoder:\n",
    "        X_encoded = encoder.fit_transform(X)\n",
    "    else:\n",
    "        X_encoded = X\n",
    "\n",
    "    # Normalizzazione dei dati (opzionale)\n",
    "    if scaler:\n",
    "        X_scaled = scaler.fit_transform(X_encoded)\n",
    "    else:\n",
    "        X_scaled = X_encoded\n",
    "\n",
    "    # Definizione della k-fold cross-validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    # Esecuzione della k-fold cross-validation\n",
    "    cv_results = cross_val_score(classifier, X_scaled, y, cv=kf, scoring='accuracy')\n",
    "'''\n",
    "    # Visualizzazione dei risultati\n",
    "    print(f'Accuratezza per ogni fold: {cv_results}')\n",
    "    print(f'Accuratezza media: {cv_results.mean()}')\n",
    "    print(f'Deviazione standard dell\\'accuratezza: {cv_results.std()}')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NEAREST NEIGHBOOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suddividi il dataset in set di addestramento e set di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(ASD_phenotypic, ASD_diagnosis['DX_GROUP'], test_size=0.3, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "# Definizione delle metriche da utilizzare come scoring\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1_score': make_scorer(f1_score)\n",
    "}\n",
    "# Identifica le colonne categoriche\n",
    "#categorical_columns = ASD_phenotypic.select_dtypes(include=['object']).columns\n",
    "\n",
    "categorical_columns = X_train.select_dtypes(include=['object']).columns\n",
    "'''\n",
    "# Definisci il preprocessing delle colonne\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', RobustScaler(), ~ASD_phenotypic.columns.isin(categorical_columns)),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ])'''\n",
    "\n",
    "# Definisci il preprocessing delle colonne\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', RobustScaler(), ~X_train.columns.isin(categorical_columns)),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Definisci il pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "\n",
    "# Definizione dei parametri della griglia da esplorare\n",
    "parameters = {'classifier__n_neighbors': [3, 5, 7, 9, 11]}  # Valori di n_neighbors da esplorare\n",
    "\n",
    "k_fold_cross_validation(X_train, y_train, pipeline)\n",
    "#k_fold_cross_validation(ASD_phenotypic, ASD_diagnosis, pipeline)\n",
    "\n",
    "# Creazione dell'oggetto GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, scoring=scoring, refit='accuracy')\n",
    "\n",
    "# Esecuzione della ricerca a griglia\n",
    "#grid_search.fit(ASD_phenotypic, ASD_diagnosis['DX_GROUP'])\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "print(\"Risultati della cross-validation per tutte le combinazioni di iperparametri:\")\n",
    "\n",
    "means_accuracy = grid_search.cv_results_['mean_test_accuracy']\n",
    "stds_accuracy = grid_search.cv_results_['std_test_accuracy']\n",
    "means_precision = grid_search.cv_results_['mean_test_precision']\n",
    "means_recall = grid_search.cv_results_['mean_test_recall']\n",
    "means_f1_score = grid_search.cv_results_['mean_test_f1_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "\n",
    "for mean_acc, std_acc, mean_prec, mean_rec, mean_f1, params in zip(means_accuracy, stds_accuracy, means_precision, means_recall, means_f1_score, params):\n",
    "    print(f\"Parametri: {params}, Accuratezza media: {mean_acc:.3f} (±{std_acc:.3f}), Precision media: {mean_prec:.3f}, Richiamo medio: {mean_rec:.3f}, F1-score medio: {mean_f1:.3f}\")\n",
    "\n",
    "print(\"\\nMiglior parametro trovato:\")\n",
    "print(\"Numero di vicini:\", grid_search.best_params_['classifier__n_neighbors'])\n",
    "print(\"Accuratezza media con il miglior parametro:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miglior modello trovato\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Calcola le previsioni del miglior modello sul set di test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcola la matrice di confusione\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualizzazione della matrice di confusione\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=['Control', 'ASD'], yticklabels=['Control', 'ASD'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola le metriche di valutazione sul set di test\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "precision_test = precision_score(y_test, y_pred)\n",
    "recall_test = recall_score(y_test, y_pred)\n",
    "f1_score_test = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance sul set di test:\")\n",
    "print(\"Accuracy:\", accuracy_test)\n",
    "print(\"Precisione:\", precision_test)\n",
    "print(\"Recall:\", recall_test)\n",
    "print(\"F1 Score:\", f1_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visualizzare l'effetto del modello sui dati attraverso un grafico di decisione\n",
    "\n",
    "# Riduzione della dimensione a 2D usando PCA (se ci sono più di due caratteristiche)\n",
    "pca = PCA(n_components=2)\n",
    "ASD_phenotypic_2d = pca.fit_transform(ASD_phenotypic)\n",
    "\n",
    "# Definizione del pipeline con PCA e il miglior modello trovato\n",
    "pipeline_2d = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', PCA(n_components=2)),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=grid_search.best_params_['classifier__n_neighbors']))\n",
    "])\n",
    "\n",
    "# Adattamento del pipeline\n",
    "pipeline_2d.fit(ASD_phenotypic, ASD_diagnosis['DX_GROUP'])\n",
    "\n",
    "# Creazione di una meshgrid per la visualizzazione delle regioni di decisione\n",
    "h = .02  # passo della meshgrid\n",
    "x_min, x_max = ASD_phenotypic_2d[:, 0].min() - 1, ASD_phenotypic_2d[:, 0].max() + 1\n",
    "y_min, y_max = ASD_phenotypic_2d[:, 1].min() - 1, ASD_phenotypic_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predizione su ogni punto della meshgrid\n",
    "Z = pipeline_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Creazione di un colormap per la visualizzazione delle regioni di decisione\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "# Visualizzazione delle regioni di decisione\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contourf(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Visualizzazione dei punti di addestramento\n",
    "scatter = plt.scatter(ASD_phenotypic_2d[:, 0], ASD_phenotypic_2d[:, 1], c=ASD_diagnosis['DX_GROUP'], cmap=cmap_bold, edgecolor='k', s=20)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=['Control', 'ASD'])\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Decision Boundaries with k-NN')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN con feature selection SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Suddividi il dataset in set di addestramento e set di test\n",
    "X_train, X_test, y_train, y_test = train_test_split(ASD_phenotypic, ASD_diagnosis['DX_GROUP'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Definisci il modello\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "# Definisci la Sequential Feature Selector\n",
    "sfs = SequentialFeatureSelector(classifier,\n",
    "                                k_features='best',  # Scegli il miglior set di features\n",
    "                                forward=True,  # Aggiungi le features in modo progressivo\n",
    "                                floating=False,  # Non utilizzare la ricerca flottante\n",
    "                                verbose=2,  # Mostra informazioni dettagliate\n",
    "                                scoring='accuracy',  # Criterio di performance\n",
    "                                cv=5)  # Cross-validation\n",
    "\n",
    "# Addestra la Sequential Feature Selector\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "# Visualizza le features selezionate\n",
    "selected_features = X_train.columns[list(sfs.k_feature_idx_)]\n",
    "print(\"Features selezionate:\", selected_features)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creazione dell'istanza del regressore lineare\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Definizione delle metriche da utilizzare come scoring\n",
    "scoring = {\n",
    "    'neg_mean_squared_error': 'neg_mean_squared_error',  # Per la regressione, di solito si usa l'errore quadratico medio negativo\n",
    "    'r2_score': 'r2'  # Coefficiente di determinazione (R²)\n",
    "}\n",
    "\n",
    "# Definisci il preprocessing delle colonne come hai fatto prima\n",
    "\n",
    "# Definisci il pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', regressor)\n",
    "])\n",
    "'''\n",
    "# Definizione dei parametri della griglia da esplorare\n",
    "parameters = {\n",
    "    'regressor__normalize': [True, False]  # Ad esempio, è possibile esplorare l'opzione di normalizzazione del regressore lineare\n",
    "}\n",
    "'''\n",
    "# Esegui la k-fold cross-validation e la ricerca dei parametri ottimali\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, scoring=scoring, refit='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "print(\"Risultati della cross-validation per tutte le combinazioni di iperparametri:\")\n",
    "\n",
    "means_mse = -grid_search.cv_results_['mean_test_neg_mean_squared_error']  # Converti l'errore quadratico medio negativo in positivo\n",
    "stds_mse = grid_search.cv_results_['std_test_neg_mean_squared_error']\n",
    "means_r2 = grid_search.cv_results_['mean_test_r2']\n",
    "params = grid_search.cv_results_['params']\n",
    "\n",
    "for mean_mse, std_mse, mean_r2, params in zip(means_mse, stds_mse, means_r2, params):\n",
    "    print(f\"Parametri: {params}, MSE medio: {mean_mse:.3f} (±{std_mse:.3f}), R² medio: {mean_r2:.3f}\")\n",
    "\n",
    "print(\"\\nMiglior parametro trovato:\")\n",
    "print(\"Parametri ottimali:\", grid_search.best_params_)\n",
    "print(\"MSE medio con i parametri ottimali:\", means_mse[grid_search.best_index_])  # MSE medio del miglior modello trovato\n",
    "print(\"R² medio con i parametri ottimali:\", means_r2[grid_search.best_index_])  # R² medio del miglior modello trovato\n",
    "\n",
    "# Miglior modello trovato\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Calcola le previsioni del miglior modello sul set di test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola la matrice di confusione\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualizzazione della matrice di confusione\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=['Control', 'ASD'], yticklabels=['Control', 'ASD'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola le metriche di valutazione sul set di test\n",
    "accuracy_test = accuracy_score(y_test, y_pred)\n",
    "precision_test = precision_score(y_test, y_pred)\n",
    "recall_test = recall_score(y_test, y_pred)\n",
    "f1_score_test = f1_score(y_test, y_pred)\n",
    "print(\"Performance sul set di test:\")\n",
    "print(\"Accuracy:\", accuracy_test)\n",
    "print(\"Precisione:\", precision_test)\n",
    "print(\"Recall:\", recall_test)\n",
    "print(\"F1 Score:\", f1_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Random Forest classifier, I need to have only numerical features, so we will use one-hot-encoding to turn the categorical features (which aren't ordinal) into numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_encoded = of.One_hot_encoding(ASD_phenotypic)\n",
    "ASD_phenotypic_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we split the data into training, validation and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the dataset into train+validation and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(ASD_phenotypic_encoded, ASD_diagnosis, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the train+validation set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to check the balance btw classes for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts_test = y_test.value_counts(normalize=True)\n",
    "class_counts_train = y_train.value_counts(normalize=True)\n",
    "class_counts_val = y_val.value_counts(normalize=True)\n",
    "\n",
    "# Stampa il conteggio delle classi per DX_GROUP\n",
    "print(\"Class proportions for:\")\n",
    "print(\"- test set: \" + str(class_counts_test))\n",
    "print(\"- train set: \" + str(class_counts_train))\n",
    "print(\"- val set: \" + str(class_counts_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_clf = RandomForestClassifier(n_estimators=10)\n",
    "random_clf = random_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained random forest classifier to predict labels for the validation set\n",
    "y_pred = random_clf.predict(X_val)\n",
    "\n",
    "# Calculate the accuracy of the classifier on the validation set\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy on the validation set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_val, \n",
    "                                        y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier on the validation set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy on the testing set:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, \n",
    "                                        y_pred)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
