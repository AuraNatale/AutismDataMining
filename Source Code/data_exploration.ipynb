{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt #for the plots\n",
    "import seaborn as sns \n",
    "import re\n",
    "import OurFunctions as of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_original = pd.read_csv(os.path.join('DataSets','Phenotypic Datasets','ASD','ASD_phenotypic.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All'interno del dataset, abbiamo 2 features ( DX_GROUP e DSM_IV_TR) che sono i nostri\n",
    "controlli. Quindi vogliamo splittare il dataset originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop delle colonne DX_GROUP e DSM_IV_TR da ASD_phenotypic\n",
    "ASD_phenotypic = ASD_phenotypic_original.drop(columns=['DX_GROUP', 'DSM_IV_TR'])\n",
    "\n",
    "# Creazione di ASD_clinical\n",
    "ASD_clinical = ASD_phenotypic_original[['DX_GROUP', 'DSM_IV_TR']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizziamo, non completamente, il nostro dataset\n",
    "#e otteniamone la dimensione: prima info utile\n",
    "ASD_phenotypic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic.head() #in order to underline features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otteniamo le informazioni relative al dataset\n",
    "ASD_phenotypic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_clinical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_clinical.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OVERVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 1112 raws anf 74 colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converti tutte le stringhe delle colonne categoriche in maiuscolo \n",
    "category_columns_upper = ASD_phenotypic.select_dtypes(include='object').apply(lambda x: x.str.upper())\n",
    "\n",
    "# Sostituisci le colonne originali con quelle convertite in maiuscolo\n",
    "ASD_phenotypic[category_columns_upper.columns] = category_columns_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check the presence of missing values catalogated as None or numpy.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of NANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo dei valori mancanti e ordinamento\n",
    "nan_values = ASD_phenotypic.isna().sum()\n",
    "columns_with_nan_sorted = nan_values.sort_values(ascending=False)\n",
    "\n",
    "# Selezione delle colonne numeriche e categoriche\n",
    "numeric_columns, categorical_columns, ASD_phenotypic = of.select_columns(ASD_phenotypic)\n",
    "\n",
    "# Plot dei valori mancanti\n",
    "of.plot_missing_values(columns_with_nan_sorted, numeric_columns, legend=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice the huge amount of missing values in dataset. For this reason we can delete apriori those features containing an high percentage of missing values (< 50%>) in order to proceed in a more easy and consistent way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brutal Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola il numero totale di righe nel DataFrame\n",
    "total_rows = len(ASD_phenotypic)\n",
    "\n",
    "# Calcola il numero massimo di valori mancanti consentiti (65%)\n",
    "max_missing_values = total_rows * 0.65\n",
    "\n",
    "# Trova le colonne con un numero di valori mancanti superiore al limite consentito\n",
    "columns_to_drop = []\n",
    "for column, missing_count in columns_with_nan_sorted.items():\n",
    "    if missing_count > max_missing_values:\n",
    "        columns_to_drop.append(column)\n",
    "\n",
    "# Rimuovi le colonne con un numero di valori mancanti eccessivo\n",
    "ASD_phenotypic_filtered = ASD_phenotypic.drop(columns=columns_to_drop)\n",
    "\n",
    "# Stampa le colonne rimosse\n",
    "print(\"Le seguenti colonne sono state rimosse perché hanno più del 65% dei valori mancanti:\")\n",
    "for column in columns_to_drop:\n",
    "    print(column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo dei valori mancanti e ordinamento\n",
    "nan_values_filtered = ASD_phenotypic_filtered.isna().sum()\n",
    "columns_with_nan_sorted_filtered = nan_values_filtered.sort_values(ascending=False)\n",
    "\n",
    "# Selezione delle colonne numeriche e categoriche\n",
    "numeric_columns_filtered, categorical_columns_filtered, ASD_phenotypic_filtered = of.select_columns(ASD_phenotypic_filtered)\n",
    "\n",
    "# Plot dei valori mancanti\n",
    "of.plot_missing_values(columns_with_nan_sorted_filtered, numeric_columns_filtered, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_values_filtered.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can investigate if there are subjects with a huge amount of missing values\n",
    "and in case delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo dei valori mancanti per soggetto anziché per feature\n",
    "nan_values_per_subject = ASD_phenotypic_filtered.T.isna().sum()\n",
    "\n",
    "# Ordinamento dei valori mancanti\n",
    "subjects_with_nan_sorted = nan_values_per_subject.sort_values(ascending=False)\n",
    "\n",
    "\n",
    "of.plot_missing_values(subjects_with_nan_sorted, nan_values_per_subject, legend=False)\n",
    "plt.ylabel('Subjects')\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we notice that we can't delete any subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CATEGORICAL EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ciclo su tutte le colonne di tipo 'category'\n",
    "for column in categorical_columns_filtered:\n",
    "    # Stampa il nome della colonna\n",
    "    print(\"Feature:\", column)\n",
    "    # Stampa i valori unici della colonna\n",
    "    unique_values = ASD_phenotypic_filtered[column].unique()\n",
    "    for value in unique_values:\n",
    "        print(value)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploding categorical features, we notice the presence of value -9999, commonly used to denote missing data or values out of range, so we are going to consider them as NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ottieni i nomi delle colonne categoriche come una lista\n",
    "categorical_column_names = categorical_columns_filtered.tolist()\n",
    "\n",
    "'''We notice the presence of -9999 value in several features. \n",
    "In order to prevent this also in numerical features we evaluate this value as a NaN in \n",
    "the entire ASD_phenotypic_filtered'''\n",
    "\n",
    "for column in ASD_phenotypic_filtered:\n",
    "    \n",
    "    # Replace -9999 and \"-9999\" with NaN\n",
    "    ASD_phenotypic_filtered[column] = ASD_phenotypic_filtered[column].replace(['-9999', -9999], np.NaN)\n",
    "    \n",
    "\n",
    "'''We checked if the presence changing -9999 as NaN at the starting point produce relevant changes\n",
    "in distribution of Missing Values in Dataset and subesequent brutal filtering and we found that\n",
    "the changes are negligible. '''\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand better how to treat the information gived by this categorical variables we are interested in know which values are stored in this features. We will analyze all of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo dei valori mancanti e ordinamento\n",
    "nan_values_filtered = ASD_phenotypic_filtered.isna().sum()\n",
    "columns_with_nan_sorted_filtered = nan_values_filtered.sort_values(ascending=False)\n",
    "\n",
    "# Selezione delle colonne numeriche e categoriche\n",
    "numeric_columns_filtered, categorical_columns_filtered, ASD_phenotypic_filtered = of.select_columns(ASD_phenotypic_filtered)\n",
    "\n",
    "\n",
    "# Plot dei valori mancanti\n",
    "of.plot_missing_values(columns_with_nan_sorted_filtered, numeric_columns_filtered, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the implemented tolist, we can acced to specific elements.\n",
    "We prefer create viasual subsections in order to manage these features, but we could implement a 'for logic' in order to guarantee a correct automatic work also in case of modifications on dataset.\n",
    "\n",
    "For each categorical feature, we want to investigate the amount of informations given. We suppose that for our specific scope we could drop some uninformative features, but we want to proof it. In which way? \n",
    "- Evaluating the amount of info considering Nan as Nan\n",
    "- Changing Missing values with specific feature engineering rules\n",
    "- Evaluating the amount of info with Nan evalueted\n",
    "\n",
    "We use Entropy logic.\n",
    "If both have high level of entropy we can drop the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SITE_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SITE_ID refers to the place where the data from the subject was recluted. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accesso a una specifica colonna categorica utilizzando la lista di nomi\n",
    "specific_category_column = ASD_phenotypic_filtered[categorical_column_names[0]].value_counts(dropna=False)\n",
    "specific_category_column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is data that has been collected from the same center that we decide to unify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a function to replace the categories for the indicated cases\n",
    "\n",
    "def replace_categories(category):\n",
    "    if \"UCLA\" in category:\n",
    "        return \"UCLA\"\n",
    "    if \"LEUVEN\" in category:\n",
    "        return \"LEUVEN\"\n",
    "    if \"UM\" in category:\n",
    "        return \"UM\"\n",
    "    else:\n",
    "        return category\n",
    "\n",
    "# Then we apply the replace function\n",
    "ASD_phenotypic_filtered[categorical_column_names[0]] = ASD_phenotypic_filtered[categorical_column_names[0]].apply(replace_categories).astype('category')\n",
    "\n",
    "# Now we check the new order\n",
    "specific_category_column = ASD_phenotypic_filtered[categorical_column_names[0]].value_counts(dropna=False)\n",
    "specific_category_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HANDEDNESS_CATEGORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HANDEDNESS_CATEGORY refers to the handedness of the subject. We don't really know if there is a correlation or not between the Autism Disease and the handnedness of the subject and as it is a caracteristic of the subject itselfs and not of the specific site of analysis as in the previous case, we decide to work with this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accesso a una specifica colonna categorica utilizzando la lista di nomi\n",
    "specific_category_column = ASD_phenotypic_filtered[categorical_column_names[1]].value_counts(dropna=False)\n",
    "specific_category_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are incongruences for the Ambidextreus group, so we will replace them (Mixed and L->R) for Ambi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to replace categories and NaN values\n",
    "def replace_categories_and_nan(category):\n",
    "    if category in ['MIXED', 'L->R']:\n",
    "        return 'AMBI'\n",
    "    else:\n",
    "        return category\n",
    "\n",
    "# Apply the custom function to the categorical column\n",
    "ASD_phenotypic_filtered[categorical_column_names[1]] = ASD_phenotypic_filtered[categorical_column_names[1]].apply(replace_categories_and_nan).astype('category')\n",
    "\n",
    "# Display the new result\n",
    "specific_category_column = ASD_phenotypic_filtered[categorical_column_names[1]].value_counts(dropna=False)\n",
    "specific_category_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be applied at the final????\n",
    "\n",
    "We can see that we have values for R, L and Ambi, Mixed, L->R. The dataset include as a feature also a handness score where right-handed subjects has positive score (max = 100), left-handed subjects negative score (min = -100) and ambidextreus subjects has 0 score. \n",
    "\n",
    "To be coherent with that categorization and can properly evaluate if one of those features contain redudant information or that can be merged in some manner, we decide to assign to R values the number \"100\", to L values the number \"-100\" and to Ambi, Mixed, L->R the number \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIQ_TEST_TYPE, VIQ_TEST_TYPE and PIQ_TEST_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIQ_TEST_TYPE, VIQ_TEST_TYPE and PIQ_TEST_TYPE refers to the type of test that each center chose to get the information of FIQ_TEST, VIQ_TEST and PIQ_TEST respectively. As we want our clustering algorithm to be as most general as possible, we want to be able to categorize subjects in despise of the test used by the centers to get the data. So we decide to drop this feature as well.\n",
    "\n",
    "Note that if in a future we will be interested in to analyze if there are differences between the clustering score obtained using the result for each difference test we'll can retrieve the information opportunely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (2,5):\n",
    "    specific_category_column = ASD_phenotypic_filtered[categorical_column_names[i]].value_counts(dropna=False)\n",
    "    print(specific_category_column)\n",
    "    print('______________________________________\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a function to replace the categories for the indicated cases\n",
    "\n",
    "def replace_categories(category):\n",
    "    if pd.isna(category):  # Controlla se il valore è NaN\n",
    "        return category  # Se è NaN, restituisci lo stesso valore\n",
    "    if \"WASI\" in category:\n",
    "        return \"WASI\"\n",
    "    if \"WISC\" in category:\n",
    "        return \"WISC\"\n",
    "    if \"WAIS\" in category:\n",
    "        return \"WAIS\"\n",
    "    if \"DAS\" in category:\n",
    "        return \"DAS\"\n",
    "    if \"HAWIK\" in category:\n",
    "        return \"HAWIK\"\n",
    "    if \"PPVT\" in category:\n",
    "        return \"PPVT\"\n",
    "    if \"RAVENS\" in category:\n",
    "        return \"RAVENS\"\n",
    "   \n",
    "    else:\n",
    "        return category\n",
    "\n",
    "for i in range (2,5):\n",
    "    ASD_phenotypic_filtered[categorical_column_names[i]] = ASD_phenotypic_filtered[categorical_column_names[i]].apply(replace_categories).astype('category')\n",
    "    specific_category_column = ASD_phenotypic_filtered[categorical_column_names[i]].value_counts(dropna=False)\n",
    "    print(specific_category_column)\n",
    "    print('______________________________________\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CURRENT_MED_STATUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature indicates if the subject is taking any medication or not. If the subject doesn't take any medication is labeled with a \"0\" in the other case with a \"1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accesso a una specifica colonna categorica utilizzando la lista di nomi\n",
    "specific_category_column = ASD_phenotypic_filtered[categorical_column_names[5]].value_counts(dropna=False)\n",
    "specific_category_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the only attribute that is not numeric is the \"`\", we will catalogate it as a NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to replace categories and NaN values\n",
    "def replace_categories_and_nan(category):\n",
    "    if category in [\"`\"]:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return category\n",
    "\n",
    "# Apply the custom function to the categorical column\n",
    "ASD_phenotypic_filtered[categorical_column_names[5]] = ASD_phenotypic_filtered[categorical_column_names[5]].apply(replace_categories_and_nan).astype('float64')\n",
    "\n",
    "# Display the new result\n",
    "specific_category_column = ASD_phenotypic_filtered[categorical_column_names[5]].value_counts(dropna=False)\n",
    "specific_category_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_filtered.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUMERICAL EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the dataset: Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look on the general statistics for the numerical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASD_phenotypic_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menaging Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to handle missing values. But how?\n",
    "Is really necessary to fullfill all of them? Can we maybe make some feature selection previously?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IQ Test Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use features FIQ, VIQ and PIQ in order to fill some values in FIQ-TEST-TYPE, VIQ-TEST-TYPE, PIQ-TEST-TYPE.\n",
    "Since the presence of more missing values in \"Type\" features, we make a comparison for each couple of features. For instance: if for FIQ there is a value and for FIQ-TEST-TYPE there is a missing one, we fill it with the MODE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista delle coppie di features da controllare\n",
    "feature_pairs = [\n",
    "    ('FIQ_TEST_TYPE', 'FIQ'),\n",
    "    ('PIQ_TEST_TYPE', 'PIQ'),\n",
    "    ('VIQ_TEST_TYPE', 'VIQ')]\n",
    "\n",
    "# Iteriamo su ogni coppia di features\n",
    "for test_type_col, score_col in feature_pairs:\n",
    "    # Iteriamo su ogni riga del DataFrame\n",
    "    for index, row in ASD_phenotypic_filtered.iterrows():\n",
    "        # Controlliamo se il valore nella colonna 'test_type_col' è mancante\n",
    "        if pd.isnull(row[test_type_col]):\n",
    "            # Se il valore nella colonna 'score_col' è presente\n",
    "            if not pd.isnull(row[score_col]):\n",
    "                # Calcoliamo la moda di 'test_type_col'\n",
    "                mode_test_type = ASD_phenotypic_filtered[test_type_col].mode()[0]\n",
    "                # Sostituiamo il valore mancante nella colonna 'test_type_col' con la moda\n",
    "                ASD_phenotypic_filtered.at[index, test_type_col] = mode_test_type\n",
    "            # Se entrambi i valori in 'test_type_col' e 'score_col' sono mancanti\n",
    "            elif pd.isnull(row[score_col]):\n",
    "                # Verifichiamo se \"NOT_AVAILABLE\" è già presente tra le categorie della colonna\n",
    "                if \"NOT_AVAILABLE\" not in ASD_phenotypic_filtered[test_type_col].cat.categories:\n",
    "                    # Aggiungiamo \"NOT_AVAILABLE\" come nuova categoria\n",
    "                    ASD_phenotypic_filtered[test_type_col] = ASD_phenotypic_filtered[test_type_col].cat.add_categories(\"NOT_AVAILABLE\")\n",
    "                # Assegniamo la categoria 'NOT_AVAILABLE' a 'test_type_col'\n",
    "                ASD_phenotypic_filtered.at[index, test_type_col] = 'NOT_AVAILABLE'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make random forest for features selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''CORRELATION MATRIX\n",
    "numeric = ASD_phenotypic.select_dtypes(include=['float64',\"int64\"]).dropna()\n",
    "numeric.T\n",
    "f,ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(numeric.corr(), \n",
    "            annot=True, \n",
    "            linewidths=.5, \n",
    "            fmt= '.2f',\n",
    "            ax=ax,\n",
    "            vmin=-1, \n",
    "            vmax=1,\n",
    "            cmap = \"coolwarm\")\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
